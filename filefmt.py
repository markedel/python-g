import ast, astpretty
import re
import io
import tokenize
import numbers
import tkinter.messagebox
import comn
import icon

SINGLE_QUOTE_STRING = 1
DOUBLE_QUOTE_STRING = 2
TRIPLE_SINGLE_QUOTE_STRING = 3
TRIPLE_DOUBLE_QUOTE_STRING = 4

# Additional indent to continue a statement-comment
STMT_COMMENT_INDENT = 4

# Attach per-icon comments as statement comments until display/edit code catches up
NO_ICON_COMMENTS = True

# Base name for identifier substituted for $Entry$ and $Ctx$ macros
PLACEHOLDER_NAME_TEMPLATE = "___pyg_placeholder_ident_"
placeholderNamePattern = re.compile("%s(\\d+)" % PLACEHOLDER_NAME_TEMPLATE)

ctxMacroPattern = re.compile('\\$Ctx[(:]')

# Variable names used for faking out the Python parser to parse free attributes,
# function call, and comprehensions
ATTR_PARSE_STUB = '___pyg_attr_parse_stub'
FN_CALL_PARSE_STUB = '___pyg_fn_call_parse_stub'
IMPORT_NAME_STUB = '___pyg_import_name_parse_stub'
CPRH_PARSE_STUB = '___pyg_cprh_parse_stub'

# Letter codes used in Ctx, Entry, and @ macros; to drive parsing of macro-paren-enclosed
# code (code that Python considers incompatible with the parent context and would not
# be able to parse):
#   a   attribute
#   s   as clause
#   d   dictionary element
#   c   comprehension clause
#   e   expression
#   f   function argument assignment or **
#   i   "import from" relative module syntax: ...x
# In Ctx and Entry macros, omitting the parse context type implies 'e'.
macroArgContextTypes = {'a', 's', 'd', 'c', 'e', 'f', 'i'}

# Dark Unicode arrow for inserting in code lines to show the location of errors in error
# dialogs (Python's normal method using a caret is problematic with proportional fonts).
ERR_START_ARROW = '\U0001F882'
ERR_END_ARROW = '\U0001F880'

# Macros for all windows pre-registered with registerBuiltInMacro
builtInMacros = {}

# AST nodes whose text syntax includes parens (mapped to the name of the field(s) that
# contain the arguments that appear within the parens).
astNodesWithParens = {ast.Call:('args', 'keywords'), ast.Tuple:('elts',),
    ast.FunctionDef:('args',), ast.AsyncFunctionDef:('args',), ast.ClassDef:('bases',)}

class MacroParser:
    macroPattern = re.compile("\\$([^$]+)\\$")
    posMacroPattern = re.compile("@(([-+])\\d*)(([-+])\\d*)(:([asdcefi])?)?(\\()?")
    leftArgOpPattern = re.compile(
        "\\+|-|/|%|\\*|<|>|\\||\\^|&|is|in|and|or|if|=|!=|\\(|\\.|\\[")

    def __init__(self):
        self.macroList = builtInMacros.copy()

    def addMacro(self, name, subs="", iconCreateFn=None):
        """Add a macro to annotate and extend the save-file and pasted-text format beyond
        the base Python syntax.  The save-file format extends Python with macros of the
        form $name:argString$.  name is composed of the same set of characters as Python
        identifiers. Macros that skip the name ($:args$) provide (mostly layout-ralated)
        information to the built-in icon creation functions for Python itself.  The colon
        separates the macro name from its arguments, and may be omitted if there are no
        arguments to pass.  The format of the argument string (argString) is entirely up
        to the implementer, but must not contain the "$" character.  The argument, subs,
        provides text to replace the macro before parsing with the Python parser, and
        may alternatively be passed as a function to generate the substitution string
        from the macro argString.  Since the ultimate goal is to create icons, string
        substitution is needed only in rare cases to temporarily support sub-structure
        (such as statement blocks) and get it to pass initial parsing.  Most of the work
        will be done in the icon creation function (iconCreateFn).  Since macros are
        associated with AST nodes based on their location in the save-file, there is
        a special case for nodes generated by text substitution by the macro, itself.
        To reference a python construct inserted by the macro, the substitution text
        should place a '$' character before the item to be marked.  The '$' will be
        removed in the substitution process, and the macro data will be associated
        with the python code that followed it in the inserted text.  Some macros can also
        accept code arguments.  Code arguments are introduced by adding a right paren
        before the ending $, and then either continued with $)($ or terminated with a
        matching $)$.  Code arguments are passed to the icon creation function in
        (annotated) AST form.  iconCreateFn should be a function with parameters for
        astNode, macroArgs, argAsts, and window."""
        self.macroList[name] = subs, iconCreateFn

    def expandMacros(self, text, startIdx=0, startLineNum=1):
        """Takes text in python_g clipboard/save-file text format, expands macros until
        either the end of text or $($ or $@$ macro.  Returns four items:
            1) The macro-expanded text
            2) An object for looking up macro annotation (name, arguments, and icon
               creation function) given an AST node resulting from parsing the text.
            3) A list whose index is line number in the macro-expanded version of the
               text and whose content is line number in the original ext (before
               expansion).
            4) The ending index (end of text or start of $@$ or $)$ macro).
            5) The line number where parsing stopped.
        Raises MacroFailException on failure, as well as parsing exceptions for code
        args, which are parsed to AST form before returning.  It is worth emphasizing,
        because I'm sure this is going to cause confusion, that for macro code arguments,
        this *also* does Python AST parsing and annotation.  From a user perspective this
        may cause somewhat unexpected ordering of error messages, and from an internal
        code perspective, an unexpected order of execution.  This is done because the
        surrounding code is parsed in a single pass, so macro arguments must therefore be
        processed either before or after.  Parsing here is simpler because it avoids
        having to package and index the data for annotation and line-number translation
        that would be needed to do it after macro expansion."""
        annotations = AnnotationList()
        lineNumTranslate = [startLineNum]
        origLineStarts = [0]
        origLineNum = startLineNum
        modLineNum = 1
        modColNum = 0
        modTextFrags = []
        modFragStart = startIdx
        origIdx = startIdx
        inString = None
        inComment = False
        stopIdx = len(text)
        while origIdx < len(text):
            origChar = text[origIdx]
            if origChar == '\t' and not inComment and inString is None:
                raise MacroFailException(text, origIdx, origLineNum,
                    "Tab characters not allowed")
            if origChar == '\n':
                inComment = False
                origLineNum += 1
                lineNumTranslate.append(origLineNum)
                modLineNum += 1
                modColNum = 0
                origLineStarts.append(origIdx+1)
                origIdx += 1
            elif origChar == '$' and not inComment and inString is None:
                # Macro found.  Process it and get replacement text
                match = self.macroPattern.match(text, origIdx)
                if match is None:
                    raise MacroFailException(text, origIdx, origLineNum)
                if match.group(1)[0] in '@)':
                    stopIdx = origIdx
                    break
                replaceText, macroEndIdx, origLineNum = self._processMacro(modLineNum,
                    modColNum, text, origIdx, origLineNum, annotations)
                # Copy the text between the last macro and this one in to the output list
                textToCopy = text[modFragStart:origIdx]
                modTextFrags.append(textToCopy)
                # Copy the macro's replacement text in to the output list
                modTextFrags.append(replaceText)
                # Advance line and col for macro-substituted text (modLines, modColNum)
                modLines = replaceText.split('\n')
                for i in range(len(modLines) - 1):
                    modLineNum += 1
                    lineNumTranslate.append(origLineNum)
                if len(modLines) > 1:
                    modColNum = len(modLines[-1])
                else:
                    modColNum += len(replaceText)
                origIdx = macroEndIdx
                modFragStart = origIdx
            else:
                # While some macro languages require full ownership of the macro-
                # introducing character(s), we allow $ characters to appear in strings
                # and comments (the alternative being transforming them to $$ or similar
                # on output).  Therefore, even though we're only looking for macros, we
                # still need to do enough parsing to recognize strings and comments.
                if origChar == '#' and inString is None:
                    inComment = True
                elif origChar == '"' and not inComment:
                    if inString is None:
                        if strAt(text, origIdx-2, '"""'):
                            inString = TRIPLE_DOUBLE_QUOTE_STRING
                        elif inString != SINGLE_QUOTE_STRING:
                            inString = DOUBLE_QUOTE_STRING
                    elif inString == DOUBLE_QUOTE_STRING:
                        if not strAt(text, origIdx-1, '\\"') or \
                                strAt(text, origIdx-2, '\\'):
                            inString = None
                    elif inString == TRIPLE_DOUBLE_QUOTE_STRING:
                        if strAt(text, origIdx-2, '"""'):
                            if not strAt(text, origIdx-3, '"') or \
                                    strAt(text, origIdx-5, '""""""'):
                                inString = None
                elif origChar == "'" and not inComment:
                    if inString is None:
                        if strAt(text, origIdx-2, "'''"):
                            inString = TRIPLE_SINGLE_QUOTE_STRING
                        elif inString != DOUBLE_QUOTE_STRING:
                            inString = SINGLE_QUOTE_STRING
                    elif inString == SINGLE_QUOTE_STRING:
                        if not strAt(text, origIdx-1, "\\'") or \
                                strAt(text, origIdx-2, '\\'):
                            inString = None
                    elif inString == TRIPLE_SINGLE_QUOTE_STRING:
                        if strAt(text, origIdx-2, "'''"):
                            if not strAt(text, origIdx-3,  "'") or \
                                    strAt(text, origIdx-5, "''''''"):
                                inString = None
                # Advance to the next character and increment column count
                modColNum += 1
                origIdx += 1
        # Copy the text between the last macro and the end of the input text to the output
        modTextFrags.append(text[modFragStart:stopIdx])
        # Consolidate the output fragments in to a single string, and return it and the
        # annotation dictionary and line number translation list
        return "".join(modTextFrags), annotations, lineNumTranslate, origIdx, origLineNum

    def _processMacro(self, modLineNum, modColNum, origText, macroStartIdx, origLineNum,
            annotations):
        """Process a macro in origText between macroStartIdx and macroEndIdx, adding
        entries to annotations object for associating data from the named macro and the
        argument string with appropriate AST node.  Returns text to substitute for the
        macro before passing it on to the Python parser, and the next index and line
        number within origText after the macro.  Raises MacroFailException on error"""
        # Parse the macro.  In the case of a macro that surrounds code, here we parse
        # just the initial macro ending in '($'.
        match = self.macroPattern.match(origText, macroStartIdx)
        macroEndIdx = macroStartIdx + len(match.group(0))
        macroText = match.group(1)
        macroName, macroArgs, macroArgCodeType = self._parseMacro(macroText)
        if macroName is None:
            raise MacroFailException(origText, macroStartIdx, origLineNum,
                message='Bad macro format')
        # If the macro ended in a (, process until matching $)$
        if macroArgCodeType is None:
            macroArgCodeList = None
        else:
            macroArgCodeList, macroEndIdx, origLineNum = self._parseMacroArgCode(
                origText, macroEndIdx, macroArgCodeType, origLineNum)
        # Look up the macro in the macro list (or recognize hard-coded no-name and @
        # macros) to get or synthesize its replacement text and icon creation function.
        # Note special cases for $Empty$ and $Ctx$ macros, which encode the line+col in
        # in the stand-in name for situations where the Python parser doesn't associate
        # an AST node with the item (usually a name, such as in def, class, import...),
        # or doesn't tag it with a line and column (such as keyword assignment).
        if macroName == "":
            replaceText = ""
            iconFn = None
        elif macroName == "@":
            replaceText = "pass"
            iconFn = None
        elif macroName == "Empty":
            replaceText = makeMacroPlaceholder(modLineNum, modColNum, macroArgs)
            iconFn = lambda node, args, argAsts, win: None
        elif macroName == "Ctx":
            if macroArgCodeType not in (None, 'e', 'd', 's', 'f', 'i'):
                raise MacroFailException(origText, macroStartIdx, origLineNum,
                    message='Ctx macro only allows code argument types e, d, f, or s')
            if macroArgs is not None and macroArgs not in "KDC":
                raise MacroFailException(origText, macroStartIdx, origLineNum, message=\
                    'Ctx macro only allows argument types e, d, f, s, i, D, K, and C')
            replaceText = makeMacroPlaceholder(modLineNum, modColNum, macroArgs)
            iconFn = ctxMacroFn
        else:
            macroData = self.macroList.get(macroName)
            if macroData is None:
                raise MacroFailException(origText, macroStartIdx, origLineNum,
                    message='Macro %s not defined' % macroName)
            subs, iconFn, = macroData
            if callable(subs):
                replaceText = subs(macroArgs)
            else:
                replaceText = subs
        # If the replacement text contained a $, use that as the reference position for
        # locating the ast (and eventually, icon) to get the macro data.  Start by
        # Translating the dollar sign marker in the replacement text to an offset and
        # removing it from the text
        astMarker = replaceText.find("$")
        if astMarker == -1:
            astMarker = 0
        elif astMarker == len(replaceText) - 1:
            replaceText = replaceText[:-1]
        else:
            replaceText = replaceText[:astMarker] + replaceText[astMarker + 1:]
        # Associate the line and column of the text that will generate the AST with the
        # macro data we want to attach to it
        adjLine, adjCol = countLinesAndCols(replaceText, astMarker, modLineNum, modColNum)
        ann = macroName, macroArgs, iconFn, macroArgCodeList
        annotations.indexByStartPos(adjLine, adjCol, ann)
        # AST nodes with arguments on the left report line and column of their leftmost
        # argument (not of their own text), which is not useful for corresponding them
        # with the text that generated them.  For binary operations and assignments
        # (and text that looks like one of these, but we can't tell without parsing)
        # record, also, the rightmost position of their left argument
        if astMarker >= len(replaceText):
            # Marked AST is after macro
            isLeftArgOp = self.leftArgOpPattern.match(origText, macroEndIdx)
        else:
            # Marked AST is within macro
            isLeftArgOp = self.leftArgOpPattern.match(replaceText, astMarker)
        if isLeftArgOp:
            # Look backward from op through the expanded macro text to find the last
            # non-whitespace character
            adjLine, adjCol = self._leftArgLineCol(adjLine, adjCol, replaceText,
                astMarker)
            # If non-white text was not found within the macro replacement text, search
            # before the macro
            if adjLine == -1:
                adjLine, adjCol = self._leftArgLineCol(modLineNum, modColNum, origText,
                    macroStartIdx)
            annotations.indexByLeftArgEnd(adjLine, adjCol, ann)
        return replaceText, macroEndIdx, origLineNum

    @staticmethod
    def _leftArgLineCol(modLineNum, modColNum, text, idx):
        """Binary operators and assignments, unfortunately, do not encode the line and
        column of the operator, but of the entire expression.  The code here, marches
        backward from the index where the operator starts (idx) to find the first
        non-white, decrementing modLineNum and modColNum per corresponding newlines and
        whitespace characters found in the string (text).  If no whitespace is found,
        returns -1 for both line and column.  The calling code will index the macro data
        by for the AST using the returned line and column, which will correspond to the
        rightmost character of its left argument."""
        for i in range(idx-1, -1, -1):
            if text[i] == '\n':
                modLineNum -= 1
                for pl in range(i-1, -1, -1):
                    if text[pl] == '\n':
                        prevLineStart = pl + 1
                        break
                else:
                    prevLineStart = 0
                modColNum = i - prevLineStart
            elif text[i] in '\t ':
                modColNum -= 1
            else:
                return modLineNum, modColNum
        return -1, -1

    @staticmethod
    def _parseMacro(macroText):
        """Split a macro into name and argument components and check for legal name and
        and presence or absence of a macro paren and associated type code.  Returns tuple
        of macroName, macroArgs, and parenCtxType.  macroName returns None on parse error,
        and an empty string for a legal but unnamed macro.  macroArgs returns any macro
        content following a colon and preceding '(' and optional context type code.
        parenCtxType returns one of macroArgContextTypes for macros ending in an open
        paren (but still also includes the context type in macroArgs)."""
        if macroText[-1] == '(':
            if len(macroText) > 1 and macroText[-2] in macroArgContextTypes:
                macroArgCtxType = macroText[-2]
                endIdx = len(macroText) - 2
            else:
                macroArgCtxType = 'e'
                endIdx = len(macroText) - 1
        else:
            macroArgCtxType = None
            endIdx = len(macroText)
        if macroText[0] == '@':
            # Segment position macro
            return '@', macroText[1:endIdx], macroArgCtxType
        if macroText[0] == ':':
            # Annotation-only for built-in Python syntax
            return "", macroText[1:endIdx], macroArgCtxType
        # Split name from arguments at :
        for i, c in enumerate(macroText[:endIdx]):
            if c == ":":
                return macroText[:i], macroText[i+1:endIdx], macroArgCtxType
            if not c.isalnum() and c != '_':
                return None, None, None
        # No arguments found
        return macroText[:endIdx], None, macroArgCtxType

    def _parseMacroArgCode(self, origText, startIdx, parseCtxType, lineNum):
        """Parse text from startIdx through matching $)$ doing both macro expansion and
        conversion to Python AST.  Returns a list of top-level AST nodes and the index
        and line number where parsing stopped.  On failure, raises MacroFailException
        or ReprocSyntaxErrExcept."""
        #... Note that entry icons have multiple arguments, and this will need to be
        #    extended to recongnize $)($ form.
        # Do macro text substitution and index macro data into annotations structure.
        # Note that annotations (indexed by line and column) are relative to expanded
        # text, extracted from the macro argument, *not* the entire text buffer.
        expandedText, annotations, lineNumTranslate, endIdx, lineNum = self.expandMacros(
            origText, startIdx, lineNum)
        if endIdx + 3 > len(origText) or origText[endIdx: endIdx + 3] != '$)$':
            raise MacroFailException(origText, startIdx, lineNum,
                message='Expected end of macro argument code "$)$"')
        endIdx += 3
        # Strip leading spaces from first line.  We support whitespace padding around
        # macro arguments even though we don't normally write them that way (we do in the
        # case of a wrap between the macro and the arg, and users who hand-edit the file
        # will also expect this to work).  The Python parser, however, will see leading
        # whitespace as indent (at least in the expression case where we're not doctoring
        # it based on parseCtxType) so we need to strip it off.  We leave the newlines in
        # but prefix them with line a continuation character ('\') to help correspond
        # input lines with output lines.
        prefixNewlines = ''
        argLineNum = 1
        nStripped = 0
        for i, c in enumerate(expandedText):
            if c == '\n':
                prefixNewlines += '\\\n'
                argLineNum += 1
                nStripped = 0
            elif c != ' ':
                break
            else:
                nStripped += 1
        else:
            return (), endIdx, lineNum
        if i != 0:
            # Replace the stripped spaces and newlines with continuation newlines
            expandedText = prefixNewlines + expandedText[i:]
            # Adjust the annotations to reflect the edit (just the line containing text)
            annotations.offsetLineColIds(-nStripped, argLineNum)
        # Pass the macro-expanded text through the Python parser to convert to AST form.
        argAst = parseExpandedTextToAsts(expandedText, origText, annotations,
            lineNumTranslate, False, parseCtxType, 'macro argument')
        return (argAst,), endIdx, lineNum

    def parsePosMacro(self, text, startIdx, startLineNum):
        """Called during parsing of files or pasted text when parsing has stopped (currently
        parsing only stops at @ (pos) macro, unmatched $)$ or EOF.  Both EOF and leading
        space are handled by the parent, so all this should ever see is either $@... or
        $)...  On error raises MacroFailException or ReprocSyntaxErrExcept (when the @
        macro has a context argument).  Returns:
           1) (x, y) position of code, (0, 0) for module-associated sequence
           2) ASTS for macro code arguments (specified with by including open paren in
              macro)
           3) Index in to text where parsing should resume after the macro
           4) Line number of index where parsing should resume."""
        endLineNum = startLineNum
        match = self.macroPattern.match(text, startIdx)
        if match is None:
            raise MacroFailException(text, startIdx, startLineNum,
                message='Parsing error')
        endIdx = startIdx + len(match.group(0))
        macroText = match.group(1)
        if macroText[0] != '@':
            message = 'Unmatched $)$' if macroText[0] == ')' else 'Unexpected macro'
            raise MacroFailException(text, startIdx, startLineNum, message=message)
        match = self.posMacroPattern.fullmatch(macroText)
        if match is None:
            raise MacroFailException(text, startIdx, startLineNum,
                message="Bad format for @ (segment position) macro")
        if match.group(7) == '(':
            # the macro a code argument
            parseCtx = match.group(6)
            if parseCtx is None:
                parseCtx = 'e'
            macroArgCodeList, endIdx, endLineNum = self._parseMacroArgCode(
                text, endIdx, parseCtx, startLineNum)
        else:
            macroArgCodeList = None
        x = int(match.group(1))
        y = int(match.group(3))
        # If the macro is followed by a newline, consume that as well, to prevent it from
        # being converted to an extraneous vertical blank icon.
        while text[endIdx] == ' ':
            endIdx += 1
        if text[endIdx] == '\n':
            endIdx += 1
        return (x, y), macroArgCodeList, endIdx, endLineNum

class AnnotationList:
    """Associate macros with the ast nodes they marked."""
    def __init__(self):
        self.byStartPos = {}
        self.byLeftArgEnd = {}
        self.offsets = {}

    def indexByStartPos(self, line, col, annotation):
        """Associate macro data (annotation) with an AST whose recorded lineno and
        col_offset attributes match line and col.  Note, of course, that since the Python
        parser is run on macro expanded code, line an col are relative to that as opposed
        to relative to the original source file or text."""
        self.byStartPos[makeLineColId(line, col)] = annotation

    def indexByLeftArgEnd(self, line, col, annotation):
        """Associate macro data (annotation) with an (infix operator) AST whose left
        argument ends (per  its end_lineno and end_col_offset attributes) at line and
        col.  line and col are relative to the macro-expanded text passed to the Python
        parser."""
        self.byLeftArgEnd[makeLineColId(line, col)] = annotation

    def getAnnotations(self, node):
        """Look up macro data associated with a given AST node, based on the type of
        AST node and its reported position in the macro-expanded text passed to the
        Python parser."""
        leftNode = None
        nodeClass = node.__class__
        if nodeClass is ast.Expr:
            return None  # Expr nodes have the same offset as their content
        if nodeClass in (ast.BinOp, ast.Compare):
            leftNode = node.left
        elif nodeClass is ast.Assign:
            leftNode = node.targets[-1]
        elif nodeClass in (ast.AugAssign, ast.AnnAssign):
            leftNode = node.target
        elif nodeClass is ast.Call:
            leftNode = node.func
        elif nodeClass in (ast.Attribute, ast.Subscript):
            leftNode = node.value
        elif nodeClass is ast.IfExp:
            leftNode = node.body
        if leftNode:
            if hasattr(leftNode, 'end_lineno') and hasattr(leftNode, 'end_col_offset'):
                return self.getByLeftArgEnd(leftNode.end_lineno, leftNode.end_col_offset)
        else:
            if hasattr(node, 'lineno') and hasattr(node, 'col_offset') and \
                    not hasattr(node, 'isNakedTuple'):
                return self.getByLineAndCol(node.lineno, node.col_offset)
        return None

    def offsetLineColIds(self, numChars, lineNum=1):
        """If parsing required some sort of set-up (such as for a dictionary element,
        'as' clause, or comprehension) or adjustment (removing leading spaces from an
        expression), macro annotations will be off by the number of characters prepended
        or removed from the parse string.  Call this function to apply an offset to
        recorded column numbers coded in the lookup-keys for a given line (defaults to
        first line).  As with the AnnotationList in general, lineNum should be the line
        number of the macro-expanded text, not the original source text.  Note that this
        offset is not applied to column numbers extracted from placeholder identifiers,
        because these are (presumably) substituted before parsing."""
        if lineNum in self.offsets:
            self.offsets[lineNum] += numChars
        else:
            self.offsets[lineNum] = numChars

    def getFieldAnnotations(self, node):
        """For icons that contain fields for which the ast tree does not record line and
        column, we fall back on encoding them in the stand-in name.  Unfortunately, this
        will only work for macros that substitute such a stand-in. ($Empty$, $Ctx$ and
        $Entry$).  User-defined macros at these locations would fail, but should never
        appear directly in these fields, because the save code for icons representing
        these AST nodes will wrap anything that is not a simple identifier with a $Ctx$
        macro."""
        nodeClass = node.__class__
        if nodeClass is ast.Dict:
            fieldNames = [key.id if isinstance(key, ast.Name) else None for key in
                node.keys]
        elif nodeClass in (ast.Global, ast.Nonlocal):
            fieldNames = node.names
        elif nodeClass in (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef):
            fieldNames = (node.name,)
        elif nodeClass is ast.ImportFrom:
            fieldNames = (node.module,)  # Stand-in is never dotted
        elif nodeClass is ast.alias:
            fieldNames = (node.name, node.asname)
        elif nodeClass is ast.ExceptHandler:
            fieldNames = (node.name,)
        elif nodeClass is ast.arg:
            fieldNames = (node.arg,)
        elif nodeClass is ast.keyword:
            fieldNames = (node.arg,)
        else:
            return None
        lineColIds = [getPlaceholderId(n) for n in fieldNames]
        for lineColId in lineColIds:
            if lineColId is not None:
                break
        else:  # There are no placeholder names in the fields
            return None
        return [None if id is None else self.byStartPos[id] for id in lineColIds]

    def getByLineAndCol(self, line, col):
        if line in self.offsets:
            col -= self.offsets[line]
        return self.byStartPos.get(makeLineColId(line, col))

    def getByLeftArgEnd(self, line, col):
        if line in self.offsets:
            col -= self.offsets[line]
        return self.byLeftArgEnd.get(makeLineColId(line, col))

    def dump(self):
        print("annotations byStartPos")
        for key, val in self.byStartPos.items():
            print("   ", key >> 16, key & 0xffff, repr(val))
        print("annotations byLeftArgEnd")
        for key, val in self.byLeftArgEnd.items():
            print("   ", key >> 16, key & 0xffff, repr(val))

def makeLineColId(line, col):
    """Returns an integer identifier encoding both a line and column value."""
    return (line << 16) + col

def getLineColFromId(lineColId):
    """Decode line and column from a lineColId."""
    return lineColId >> 16, lineColId & 0xffff

def makeMacroPlaceholder(line, col, ctxMacroArgs=None):
    """Create a stand-in name to substitute for $Ctx$, $Empty$ or $Entry$ macros, where
    the Python parser would otherwise reject the content we want to put there.  These are
    coded with an ID based on line an column for situations where the parser does not
    tag an associated AST node with them, we can recover the corresponding macro data.
    While usually these macros substitute a simple identifier, macro args that include
    K, D, or C, will return keyword, dictionary, and comprehension syntax."""
    if ctxMacroArgs is not None:
        if 'K' in ctxMacroArgs:
            return PLACEHOLDER_NAME_TEMPLATE + str(makeLineColId(line, col)) + '=None'
        if 'D' in ctxMacroArgs:
            return PLACEHOLDER_NAME_TEMPLATE + str(makeLineColId(line, col)) + ':None'
        if 'C' in ctxMacroArgs:
            return 'for' + PLACEHOLDER_NAME_TEMPLATE + str(makeLineColId(line, col)) + \
                'in None'
    return PLACEHOLDER_NAME_TEMPLATE + str(makeLineColId(line, col))

def getPlaceholderId(placeholderStr):
    """Validate and decode a placeholder name.  If valid, returns the numeric ID
    generated from the line and column (used to look up corresponding macro data in the
    macro annotations dictionary.  Otherwise, returns None."""
    if placeholderStr is None:
        return None
    match = placeholderNamePattern.fullmatch(placeholderStr)
    if match is None:
        return None
    return int(match.group(1))

def parseTextToIcons(text, window, source="Pasted text", forImport=False, asModule=False):
    """Parse the given text in either .pyg (forImport=False), or .py (forImport=True)
    format, and return the created icons in a single list.  Note that this does not
    lay-out icons, but does set the position (.rect[:2]) of the first icon, which will
    be used by the layout code to position the sequence.  On error, pops up a dialog
    describing the error.  "source" is the name to use in the error dialog as the file
    (or other source) from which the text originated.  If 'asModule' is True, code before
    the first $@$ macro will be attached to the window's module anchor icon (window.
    modSeqIcon).  Returns list of top-level icons on success and None on failure."""
    pos = None if asModule else (0, 0)
    topLevelIcons = []
    startIdx = 0
    lineNum = 1
    while True:
        # In normal operation, this loop calls _parseTextToIcons to process code until
        # it reaches an @ (pos) macro, and repeats the process, adding the position
        # offsets from the pos macro to the first icon of each resulting sequence.
        # During this operation parsing errors will manifest through exceptions in
        # _parseTextToIcons, but also in parsePosMacro where the pos macro can process
        # its own code argument (for loose code fragments that would not parse as
        # statements or expressions), and in the syntax of the pos macro itself.  Because
        # _parseTextToIcons will also terminate on an unmatched $)$, parsePosMacro also
        # specifically looks for that pattern on failure, and generates a message more
        # appropriate to that particular syntax error.
        try:
            icons, parseEndIdx, lineNum = _parseTextToIcons(text, startIdx, lineNum,
                window, source, forImport)
        except ReprocSyntaxErrExcept as excep:
            tkinter.messagebox.showerror("Syntax Error", message=str(excep))
            return None
        except MacroFailException as excep:
            tkinter.messagebox.showerror("Error Parsing Macro", message=str(excep))
            return None
        if len(icons) > 0:
            if asModule and pos is None:
                if icons[0].hasSite('seqIn'):
                    window.modSeqIcon.replaceChild(icons[0], 'seqOut')
                else:
                    # (Probably only as a result of hand-edited .pyg file) the main
                    # module sequence contains something with no sequence sites
                    icons[0].rect = icon.moveRect(icons[0].rect, (10, 10))
            else:
                moveIconToPos(icons[0], pos)
            topLevelIcons += icons
        if parseEndIdx == len(text):
            return topLevelIcons
        try:
            pos, argCode, parseEndIdx, lineNum = window.macroParser.parsePosMacro(text,
                parseEndIdx, lineNum)
        except ReprocSyntaxErrExcept as excep:
            tkinter.messagebox.showerror("Syntax Error", message=str(excep))
            return None
        except MacroFailException as excep:
            tkinter.messagebox.showerror("Error Parsing Macro", message=str(excep))
            return None
        if argCode is not None:
            # @ (pos) macro had an argument.  Such arguments either can't be part of a
            # series (attributes and comprehensions), or can but shouldn't (dictionary
            # elements and "as" clauses).  Build icons for the argument and make sure
            # that nothing follows the macro but another pos macro.
            topIcon = icon.createFromAst(argCode[0], window)
            moveIconToPos(topIcon, pos)
            topLevelIcons.append(topIcon)
            while True:
                if parseEndIdx >= len(text):
                    return topLevelIcons
                c = text[parseEndIdx]
                if c == '\n':
                    lineNum += 1
                elif not c.isspace():
                    break
                parseEndIdx += 1
            if text[parseEndIdx:parseEndIdx+2] != "$@":
                tkinter.messagebox.showerror("Error Parsing Macros",
                    message=formatMacroFailMessage(text, parseEndIdx, lineNum,
                    "@ macro with code argument cannot be followed by code"))
                return None
        startIdx = parseEndIdx

def registerBuiltInMacro(name, subs="", iconCreateFn=None):
    """Internal function for adding a universal macro that will automatically be added to
    every window upon creation.  Parameters are same as MacroParser addMacro method."""
    builtInMacros[name] = subs, iconCreateFn

def _parseTextToIcons(text, startIdx, startLineNum, window, source, forImport):
    """Internal version of parseTextToIcons that returns an additional value of the
    text index at which parsing stopped (EOF or $@$ or $)$ macros), and takes an
    additional parameter (startIdx) of the text index at which to start parsing."""
    stmtList, endIdx, endLineNum = parseTextToAsts(window.macroParser, text, startIdx,
        startLineNum, source, forImport)
    if stmtList is None:
        return [], endIdx, endLineNum
    return icon.createIconsFromBodyAsts(stmtList, window), endIdx, endLineNum

def parseTextToAsts(macroParser, text, startIdx, startLineNum, source="Pasted Text",
            forImport=False):
    """Parse save-file format (from clipboard or file) starting at startIdx and reading
    either to the end of text or to $@$ or $)$ macro.  Returns a list of ast nodes and
    the index and line number at which parsing stopped (either the end of text, or the
    start of a $@$ or $($ macro).  On failure, raises MacroFailException or
    ReprocSyntaxErrExcept."""
    expandedText, annotations, lineNumTranslate, endIdx, endLineNum =\
        macroParser.expandMacros(text, startIdx, startLineNum)
    if expandedText == '' or expandedText.isspace():
        return None, endIdx, endLineNum
    #print('expanded Text:\n%s' % expandedText)
    #print('lineNumTranslate', lineNumTranslate)
    #annotations.dump()
    return parseExpandedTextToAsts(expandedText, text, annotations, lineNumTranslate,
        forImport, None, source), endIdx, endLineNum

def parseExpandedTextToAsts(expandedText, origText, annotations, lineNumTranslate,
        forImport, parseCtx, source):
    """Call the Python parser to parse macro-expanded text into AST form.  After parsing,
    it back-annotates the resulting AST nodes with macro data and information from the
    original text that the Python parser does not record, such as comments elifs, and
    original forms of strings and numeric constants that the parser canonicalizes.
    parseCtx should be set to None for parsing an entire code block, or the single-
    character designator used in Ctx and Entry macros (see macroArgContextTypes for
    description) for parsing an individual expression or code component.  Note the
    subtle difference in defaulting behavior from the macros themselves, which allow the
    context to be omitted when the argument is an expression.  Here you must pass 'e' if
    you want the body list and ast.Expr node stripped off from the return value)."""
    if parseCtx == 'a':
        maskLen = len(ATTR_PARSE_STUB)
        ctxMask = (maskLen, 0)
        expandedText = ATTR_PARSE_STUB + expandedText
        annotations.offsetLineColIds(maskLen)
    elif parseCtx == 's':
        ctxMask = (5, 5)
        expandedText = 'with ' + expandedText + ':pass'
        annotations.offsetLineColIds(5)
    elif parseCtx == 'd':
        ctxMask = (1, 1)
        expandedText = "{" + expandedText + "}"
        annotations.offsetLineColIds(1)
    elif parseCtx == 'f':
        if expandedText == '*':
            # f parse context handles both fn def and fn call arguments.  Unfortunately,
            # defs allow stand-alone '*'.  This ugly hack makes that work by giving it a
            # fake argument that the handler for ast.Starred can recognize and remove.
            expandedText += FN_CALL_PARSE_STUB
        maskLen = len(FN_CALL_PARSE_STUB) + 1
        ctxMask = (maskLen, 1)
        expandedText = FN_CALL_PARSE_STUB + '(' + expandedText + ')'
        annotations.offsetLineColIds(maskLen)
    elif parseCtx == 'i':
        ctxMask = (5, 8 + len(IMPORT_NAME_STUB))
        expandedText = 'from ' + expandedText + ' import ' + IMPORT_NAME_STUB
        annotations.offsetLineColIds(5)
    elif parseCtx == 'c':
        #... The 'c' parse context should be removed once icon substitution is capable
        #    of changing comprehension clauses back and forth with for and if stmts
        if expandedText[:3] == 'if ':
            ctxMask = (0, 5)
            expandedText += ':pass'
        else:
            maskLen = len(CPRH_PARSE_STUB) + 2
            ctxMask = (maskLen, 1)
            expandedText = '[' + CPRH_PARSE_STUB + ' ' + expandedText + ']'
            annotations.offsetLineColIds(maskLen)
    elif parseCtx in ('e', None):
        ctxMask = None
    else:
        ctxMask = None
        print('Unrecognized parse context passed to parseExpandedTextToAsts')
    try:
        modAst = ast.parse(expandedText, source)
    except SyntaxError as excep:
        raise ReprocSyntaxErrExcept(excep, lineNumTranslate, origText, ctxMask)
    except Exception as excep:
        raise ReprocSyntaxErrExcept(excep, ctxMask=ctxMask)
    if not isinstance(modAst, ast.Module):
        print("Unexpected AST returned from ast.parse")
        return None
    # AST parsing tosses comments, redundant parens, and the original entry formats for
    # various types of constants, but we need all of these.  Modify or annotate the AST
    # tree to include the dropped information
    _recoverTextDataOmittedFromAst(expandedText, modAst, annotations, forImport)
    # Annotate the nodes in the tree per the annotations list.  the attached tuple
    # format is: (macroName, macroArgs, iconCreateFn, macroArgIcons)
    for node in ast.walk(modAst):
        ann = annotations.getAnnotations(node)
        if ann is not None:
            node.macroAnnotations = ann
        fieldAnn = annotations.getFieldAnnotations(node)
        if fieldAnn is not None:
            # For ast node fields that are full-blown icon sites in Python-g but are just
            # a string (or list of strings) in the ast node structure, we annotate the
            # node with 'fieldMacroAnnotations'.
            node.fieldMacroAnnotations = fieldAnn
    if parseCtx is None:
        return modAst.body
    stmtAst = modAst.body[0]
    if parseCtx == 's':
        return stmtAst.items[0]
    elif parseCtx == 'd':
        return DictElemFakeAst(stmtAst.value.keys[0], stmtAst.value.values[0])
    elif parseCtx == 'f':
        if len(stmtAst.value.keywords) > 0:  # Handles both a=b and **a syntax
            return ArgAssignFakeAst(stmtAst.value.keywords[0])
        elif len(stmtAst.value.args) > 0:
            return stmtAst.value.args[0]  # *a processed by handler for ast.Starred
        else:
            print("Unexpected content in 'f' context AST node")
            return None
    elif parseCtx == 'i':
        return RelImportNameFakeAst(stmtAst.module, stmtAst.level)
    elif parseCtx == 'c':
        if isinstance(stmtAst, ast.If):
            return CprhIfFakeAst(stmtAst.test)
        else:
            cprh = stmtAst.value.generators[0]
            return CprhForFakeAst(cprh.target, cprh.iter, cprh.is_async)
    else:  # parseCtx in ('a', 'e'):
        return stmtAst.value

def _recoverTextDataOmittedFromAst(text, moduleAst, annotations, forImport):
    """ASTs are really for execution, not editing.  The Python parser strips important
    source information, such as comments, original forms of constants, and redundant
    parens.  Process the original text and annotate AST nodes or add new ones to enable
    the icon creation code to reproduce this information."""
    comments, elses, consts, commentOnlyLines, posToLParen, posToRParen = _extractTokens(
        text, annotations, forImport)
    line = _annotateAstWithComments(comments, elses, commentOnlyLines, moduleAst.body)
    # There may be comments left between the end of the parsed code and end of the file
    # or @pos macro range.  Append those to the body in the form of fake asts
    commentLines = _commentLinesAfter(comments, line)
    if commentLines is not None:
        for line in commentLines:
            moduleAst.body.append(CommentFakeAst(*comments[line]))
    _annotateAstConsts(consts, moduleAst)
    _annotateUserParens(moduleAst, posToLParen, posToRParen)

def _extractTokens(text, annotations, forImport):
    """ Return six dictionaries:
        1. mapping line numbers to comment
        2. mapping line numbers to else/elif/except/finally statements (the dictionary
          holds start column number)
        3. mapping line/col pairs to source strings for strings and numbers
        4. (a set, not a dict) records line numbers of lines that contain only a comment
        5. mapping line/col pairs to a list of integers uniquely identifying open/close
           paren pairs whose open paren *precedes* the token starting at (line, col).
        6. mapping line/col pairs to a list of integers uniquely identifying paren pairs
           whose close paren follows the token ending at (line, col)
    annotations argument is used to attach comment macro annotations, and to know  how to
    interpret line breaks in the column (by interpreting the macro arguments to detect
    "w" argument indicating that the comment should be wrapped)."""
    # The macro code already runs a processing pass on the entire source text, so it may
    # seem wasteful to run a whole separate one over the file to extract this additional
    # data.  However, this is much easier on tokenized code (which we can't do before
    # macro substitution).  I also suspect tokenizing is done in C code, so folding this
    # in with macro expansion might be less hackish, but not necessarily faster.
    lineNumToComment = {}
    lineNumToClause = {}
    posToConstSrcStr = {}
    posToLParen = {}
    posToRParen = {}
    freeParenCount = 0
    commentOnlyLines = set()
    # The tokenize module won't just take a text string.  It needs a utf-8 coded
    # readline function
    with io.BytesIO(text.encode('utf-8')) as f:
        tokens = tokenize.tokenize(f.readline)
        prevCommentLine = -1
        prevCommentCol = -1
        prevCommentContinuation = False
        prevKey = None
        parenStack = []
        parenLabel = None
        lastNonParenTokenEnd = None
        prevTokenWasString = None
        for token in tokens:
            if token.type == tokenize.COMMENT:
                startLine, startCol = token.start
                isLineComment = startCol == 0 or token.line[:startCol].isspace()
                if isLineComment:
                    commentOnlyLines.add(startLine)
                if len(token.string) > 1 and token.string[1] == " ":
                    commentText = token.string[2:]
                else:
                    # Most comments start "# ".  If not, capture the second character.
                    commentText = token.string[1:]
                if len(commentText) > 0 and commentText[-1] == '\\' and not forImport:
                    # A line continuation character at the end of a comment is was most
                    # likely added by the save code to indicate a wrapped line, but it
                    # can also be the second character of an escaped backslash from the
                    # user's original comment.  Stripping off the last char handles both.
                    commentText = commentText[:-1]
                ann = annotations.getByLineAndCol(startLine, startCol)
                if startLine == prevCommentLine + 1 and (prevCommentContinuation or
                        startCol == prevCommentCol and isLineComment and ann is None):
                    # Continuing previous comment, append to it
                    ann, prevText = lineNumToComment[prevKey]
                    if prevCommentContinuation:
                        lineSep = ''
                    else:
                        lineSep = '\n'
                    lineNumToComment[prevKey] = (ann, prevText + lineSep + commentText)
                else:
                    # Start of new comment
                    lineNumToComment[startLine] = (ann, commentText)
                    prevKey = startLine
                prevCommentLine = startLine
                prevCommentCol = startCol
                prevTokenWasString = None
                # We add a single backslash to indicate that we wrapped a line (which
                # then needs to be unwrapped).  We add a double backslashes to indicate
                # that the line actually ends in a backslash (which we need to preserve).
                prevCommentContinuation = not forImport and token.string[-1] == '\\' and (
                    len(token.string) == 1 or token.string[-2] != '\\')
            elif token.type == tokenize.NAME and token.string in ('elif', 'else',
                    'except', 'finally'):
                startLine, startCol = token.start
                lineNumToClause[startLine] = startCol
                prevTokenWasString = None
            elif token.type == tokenize.NUMBER:
                posToConstSrcStr[token.start] = token.string
            elif token.type == tokenize.STRING:
                if prevTokenWasString:
                    prevTokenWasString.append(token)
                    posToConstSrcStr[prevTokenWasString[0].start].append(token.string)
                else:
                    prevTokenWasString = [token]
                posToConstSrcStr[token.start] = [token.string]
            elif token.type == tokenize.NL:
                # NL is only emitted for newlines that do not end the statement
                # (continuation or blank line).
                startLine, startCol = token.start
                if startCol == 0 or token.line[:startCol].isspace():
                    # This is a blank line, log it in the comments list
                    lineNumToComment[startLine] = None, None
                    commentOnlyLines.add(startLine)
                # Note that specifically, we don't clear prevTokenWasString
            else:
                prevTokenWasString = None
            # Associate left parens with the next non-paren, non whitespace token and
            # right parens with the previous non-paren, non whitespace token.  Paren
            # pairs are labeled with a tuple containing the line and column numbers of
            # the left paren.  The code that annotates the AST transfers this data to the
            # paren-nodes it creates, where it may be needed for associating macro data
            # with cursor-parens.  The annotation code also uses the labels to check that
            # it has faithfully matched the original pairs.
            if token.type == tokenize.OP and token.exact_type == tokenize.RPAR:
                if len(parenStack) == 0:
                    print('Paren matching error in _extractTokens')
                else:
                    if lastNonParenTokenEnd is None:
                        # Empty argument list or tuple gets pending open parens and
                        # subsequent close parens keyed to left side of the close paren
                        if freeParenCount > 0:
                            posToLParen[token.start] = parenStack[-freeParenCount:]
                            freeParenCount = 0
                        lastNonParenTokenEnd = token.start
                        posToRParen[lastNonParenTokenEnd] = []
                    else:
                        endParenList = posToRParen.get(lastNonParenTokenEnd)
                        if endParenList is None:
                            posToRParen[lastNonParenTokenEnd] = []
                    matchLabel = parenStack.pop()
                    posToRParen[lastNonParenTokenEnd].append(matchLabel)
            elif token.type == tokenize.OP and token.exact_type == tokenize.LPAR:
                parenLabel = token.start
                parenStack.append(parenLabel)
                freeParenCount += 1
                lastNonParenTokenEnd = None
            elif token.type in (tokenize.INDENT, tokenize.DEDENT) or \
                    token.type == tokenize.NEWLINE:
                if len(parenStack) > 0:
                    print(f'Encountered unexpected token {token.type} within parens '
                          'in _extractTokens')
                    parenStack = []
                    freeParenCount = 0
                    lastNonParenTokenEnd = None
            elif token.type == tokenize.OP and token.exact_type == tokenize.COMMA:
                if freeParenCount != 0:
                    print('_extractTokens encountered unexpected empty comma clause')
                lastNonParenTokenEnd = None
            elif token.type != tokenize.NL:
                if freeParenCount > 0:
                    posToLParen[token.start] = parenStack[-freeParenCount:]
                    freeParenCount = 0
                lastNonParenTokenEnd = token.end
    return lineNumToComment, lineNumToClause, posToConstSrcStr, commentOnlyLines,\
        posToLParen, posToRParen

def _annotateAstWithComments(comments, clauses, commentOnlyLines, bodyAsts, startLine=0):
    """Augment the AST structures in bodyAsts with the comment data accumulated in the
    comment dictionary (comments) provided by _extractTokens.  ASTS will receive
    properties 'linecomments', 'stmtcomment', and 'iconcomment' depending upon the
    inferred relationship of the comment to the code.  Note that this will only process
    the line number range between startLine and the last line number recorded in AST
    nodes in bodyAsts.  Any comments beyond that need to be recovered by other means."""
    elseCommentProperties = ('elselinecomments', 'elsestmtcomment')
    exceptCommentProperties = ('exceptlinecomments', 'exceptstmtcomment')
    finallyCommentProperties = ('finallylinecomments', 'finallystmtcomment')
    for stmt in bodyAsts:
        if hasattr(stmt, 'decorator_list'):
            # This is a function or class def with decorators.  Since decorators are on
            # lines before the definition, they (rather than the definition stmt) get the
            # comments that precede them.
            for decorator in stmt.decorator_list:
                cmntLns = _commentLinesBetween(comments, startLine, decorator.lineno)
                if cmntLns is not None:
                    decorator.linecomments = [comments[line] for line in cmntLns]
                cmntLns = _commentLinesBetween(comments, decorator.lineno,
                    decorator.end_lineno + 1)
                if cmntLns is not None:
                    # A comment on the same line with the decorator (assume only 1)
                    decorator.stmtcomment = comments[cmntLns[0]]
                    if len(cmntLns) > 1:
                        print('Dropped second stmt comment attached to decorator: %s' %
                            comments[cmntLns[1]], '...')
                startLine = decorator.end_lineno + 1
        commentLines = _commentLinesBetween(comments, startLine, stmt.lineno)
        if commentLines is not None:
            stmt.linecomments = [comments[line] for line in commentLines]
        # Block statements' line number range covers the entire code block below the stmt
        # so we examine all of the comments between the first line after the statement,
        # and the first line of the first statement of the body, and if any of them is
        # not on a line by itself, assume that's still part of the block owning stmt, but
        # anything following it is a line comment below it.  This will fail when the
        # first statement of the body shares a line with a multi-line block-owning stmt
        # (which will only appear in cases of really bad code formatting), and when
        # there's a comment all by itself on a line between parts of the block-owning
        # stmt and not followed by one that shares a line with it (which is also bad
        # formatting, but could happen in weird cases, and will simply relocate the
        # comment to after the stmt, which is acceptable).
        if hasattr(stmt, 'body'):
            firstBodyStmtLine = max(stmt.lineno+1, stmt.body[0].lineno)
            commentLines = _commentLinesBetween(comments, stmt.lineno, firstBodyStmtLine)
            lastStmtLine = stmt.lineno
            if commentLines is not None:
                for lineNum in commentLines:
                    if lineNum not in commentOnlyLines:
                        lastStmtLine = lineNum
                # Leave commentsLines with only those associated with the statement.
                # The rest will be handled in the recursive call to process the body.
                commentLines = [ln for ln in commentLines if ln <= lastStmtLine]
        else:
            lastStmtLine = stmt.end_lineno
            commentLines = _commentLinesBetween(comments, stmt.lineno, lastStmtLine+1)
        if commentLines is None or len(commentLines) == 0:
            pass
        elif len(commentLines) == 1:
            # There is only one comment associated with the entire statement, attach
            # it to the statement
            stmt.stmtcomment = comments[commentLines[0]]
        else:
            # There are multiple comments associated with statement:  Associate each with
            # the outermost AST node entirely confined to comment line.  If that fails,
            # or if stmt is a block stmt (for which _outermostAstOnLine gives up), just
            # assume it's one big statement comment.
            commentAsts = []
            for lineNum in commentLines:
                outerAst = _outermostAstOnLine(lineNum, stmt)
                if outerAst is None:
                    break
                commentAsts.append(outerAst)
            if len(commentAsts) == len(commentLines) and not NO_ICON_COMMENTS:
                for commentAst, line in zip(commentAsts, commentLines):
                    commentAst.iconcomment = comments[line]
            else:
                commentList = [comments[line][1] for line in commentLines]
                stmt.stmtcomment = comments[commentLines[0]][0], ' '.join(commentList)
        if hasattr(stmt, 'body'):
            # Recursively process statements in code block(s)
            _annotateAstWithComments(comments, clauses, commentOnlyLines, stmt.body,
                lastStmtLine + 1)
            startLine = stmt.end_lineno + 1
            # Process else/elif/except/finally clauses after if, for, while, and try.
            # Unfortunately, the relevant AST nodes don't record the location of these,
            # so we dig them out of the source code in _extractTokens and pass the
            # recorded location here via the "clauses" dictionary.  Location of these
            # statements is needed to properly place comments before vs. after vs. on
            # the else/elif/except/finally statement.
            clauseBodies = []
            if hasattr(stmt, 'handlers') and len(stmt.handlers) > 0:
                for i, handler in enumerate(stmt.handlers):
                    lp, sp = exceptCommentProperties
                    clauseBodies.append((stmt, lp + str(i), sp + str(i), handler.body))
            if hasattr(stmt, 'orelse') and len(stmt.orelse) > 0:
                s = stmt
                if isinstance(stmt, ast.If):
                    # For elif, the only thing in the orelse code block is the generated
                    # if AST.  Disassemble these back into elif blocks
                    while len(s.orelse) == 1 and isinstance(s.orelse[0], ast.If):
                        clauseBodies.append((s, *elseCommentProperties, s.orelse[0].body))
                        s = s.orelse[0]
                if len(s.orelse) > 0:
                    clauseBodies.append((s, *elseCommentProperties, s.orelse))
            if hasattr(stmt, 'finalbody') and len(stmt.finalbody) > 0:
                clauseBodies.append((stmt, *finallyCommentProperties, stmt.finalbody))
            bodyEnd = stmt.body[-1].end_lineno
            for clauseStmt, clauseLineProp,clauseStmtProp, clauseBody in clauseBodies:
                clauseStart = clauseBody[0].lineno
                clauseLine, _col = _findClauseBetween(clauses, bodyEnd + 1, clauseStart)
                if clauseLine is None:
                    # The clause statement is not on a separate line, attach following
                    # line comments to the first statement in its associated block
                    afterClauseLine = bodyEnd + 1
                else:
                    # A clause statement was found, attach comment lines before to the
                    # clauselinecomment property and comments on it to clausestmtcomment.
                    commentLines = _commentLinesBetween(comments, bodyEnd+1, clauseLine)
                    if commentLines is not None:
                        commentList = [comments[l] for l in commentLines]
                        setattr(clauseStmt, clauseLineProp, commentList)
                    if clauseLine in comments:
                        setattr(clauseStmt, clauseStmtProp, comments[clauseLine])
                    afterClauseLine = clauseLine + 1
                # Recursively process statements in the clause's code block (and line
                # comments between the clause statement and it.
                _annotateAstWithComments(comments, clauses, commentOnlyLines, clauseBody,
                    afterClauseLine)
                bodyEnd = clauseBody[-1].end_lineno
        else:
            startLine = lastStmtLine + 1
    return startLine

class ConstAnnotator(ast.NodeVisitor):
    def __init__(self, posToSrcTable):
        self.posToSrcTable = posToSrcTable
        ast.NodeVisitor.__init__(self)

    def visit_Constant(self, node):
        if isinstance(node, ast.Str):
            origStr = self.posToSrcTable.get((node.lineno, node.col_offset))
            if origStr is not None:
                node.annSourceStrings = origStr
        elif isinstance(node.value, numbers.Number):
            srcStr = self.posToSrcTable.get((node.lineno, node.col_offset))
            if srcStr is not None:
                node.annNumberSrcStr = srcStr
        ast.NodeVisitor.visit_Constant(self, node)

    def visit_JoinedStr(self, node):
        origStr = self.posToSrcTable.get((node.lineno, node.col_offset))
        if origStr is not None:
            node.annSourceStrings = origStr
        ast.NodeVisitor.generic_visit(self, node)

    def visit_FunctionDef(self, node):
        if len(node.body) > 0 and isinstance(node.body[0], ast.Expr):
            exprAst = node.body[0]
            if isinstance(exprAst.value, ast.Constant):
                constAst = exprAst.value
                if isinstance(constAst.value, str):
                    constAst.annIsDocString = True
        ast.NodeVisitor.generic_visit(self, node)

    def visit_ClassDef(self, node):
        if len(node.body) > 0 and isinstance(node.body[0], ast.Expr):
            exprAst = node.body[0]
            if isinstance(exprAst.value, ast.Constant):
                constAst = exprAst.value
                if isinstance(constAst.value, str):
                    constAst.annIsDocString = True
        ast.NodeVisitor.generic_visit(self, node)

def _annotateAstConsts(astPosToSrcTable, astNode):
    annotator = ConstAnnotator(astPosToSrcTable)
    annotator.visit(astNode)

def _annotateUserParens(astNode, posToLParen, posToRParen, allocated=None):
    """Recursive function to traverse the AST tree annotating or adding synthetic AST
    nodes for unnecessary parens in the source code (to be created as CursorParenIcons
    or, in some cases by creating tuples instead of filling in series sites).  Uses
    posToLParen and posToRParen dictionaries created by _extractTokens to find parens
    enclosing the node.  If the node has both left and right parens, check that each of
    their values (line/col tuple) match and either annotate the AST node as surrounded
    by parens (for Tuple nodes), or add a synthetic AST that can generate an inserted
    CursorParen icon (for arithmetic parens).  Note that in the arithmetic paren case,
    while we do filter out nodes that explicitly contain parens (tuples, calls, function
    and class defs), we don't make the determination, here whether an arithmetic paren is
    necessary or not, because calculating precedences is surprisingly complex and we can
    use code that already exists for dealing with it the icon form.  Returns three lists
    containing line/col pairs representing parens: 1) unmatched left parens associated
    with (the left side of) astNode, 2) unmatched right parens associated with (the right
    side of) astNode, 3) parens matched across astNode that it thinks need to be added
    around it."""
    if allocated is None:
        allocated = set()
    if not isinstance(astNode, ast.AST):
        return None, None, None
    unmatchedLParens = []
    unmatchedRParens = []
    childNodesRequestingParens = []
    parenArgFields = astNodesWithParens.get(astNode.__class__)
    lParenInParenArgField = set()
    # Collect unmatched paren lists and paren creation requests from the child nodes
    for field, childNodes in ast.iter_fields(astNode):
        isParenArgField = parenArgFields is not None and field in parenArgFields
        if not isinstance(childNodes, (list, tuple)):
            childNodes = [childNodes]
        for i, childNode in enumerate(childNodes):
            # Recursively follow tree down, except in the case of a JoinedStr, which
            # has incorrect line/col data on component nodes, that will inappropriately
            # believe they own any parens surrounding the string.
            if isinstance(astNode, ast.JoinedStr):
                childUnmatchedLParens = childUnmatchedRParens = None
                childParensNeeded = None
            else:
                childUnmatchedLParens, childUnmatchedRParens, childParensNeeded =\
                    _annotateUserParens(childNode, posToLParen, posToRParen, allocated)
            if childUnmatchedLParens is not None:
                unmatchedLParens += childUnmatchedLParens
                if isParenArgField:
                    for paren in childUnmatchedLParens:
                        lParenInParenArgField.add(paren)
            if childUnmatchedRParens is not None:
                unmatchedRParens += childUnmatchedRParens
            if childParensNeeded is not None and len(childParensNeeded) > 0:
                childNodesRequestingParens.append((field, i, childParensNeeded))
    # Claim outer argument parens for this node if it is a type that has parens
    ownParensRemoved = False
    if astNode.__class__ in astNodesWithParens:
        # If parens match *around* the argument list (which is what happens in the
        # multi-argument case) we've found the AST node's parens.
        numArgParenMatches = min(len(unmatchedLParens), len(unmatchedRParens))
        if numArgParenMatches > 0 and unmatchedLParens[-1] in lParenInParenArgField:
            if unmatchedLParens[-1] != unmatchedRParens[0]:
                print('_annotateUserParens tried to pair unmatched argument parens, '
                    'line ', astNode.lineno)
                return None, None, None
            match = unmatchedLParens[-1]
            allocated.add(match)
            unmatchedLParens = [p for p in unmatchedLParens if p != match]
            unmatchedRParens = [p for p in unmatchedRParens if p != match]
            ownParensRemoved = True
        # If the node's parens were not found above, and there is just a single
        # argument node, and it is requesting parens: claim the outermost of those as
        # astNode's parens (except in the case of a tuple whose single element syntax
        # includes a trailing comma)
        if not ownParensRemoved and len(childNodesRequestingParens) > 0 and \
                not isinstance(astNode, ast.Tuple):
            argFields = astNodesWithParens[astNode.__class__]
            if sum([len(getattr(astNode, f)) for f in argFields]) == 1:
                ownParensRemoved = True
                childNodesRequestingParens[0][2].pop(0)
    # Create the parens requested for the child nodes not claimed, above.
    for field, idx, parensNeeded in childNodesRequestingParens:
        childNodes = getattr(astNode, field)
        if isinstance(childNodes, (list, tuple)):
            newChild = childNodes[idx]
        else:
            newChild = childNodes
        while len(parensNeeded) > 0:
            parenLineCol = parensNeeded.pop()
            newChild = UserParenFakeAst(newChild, parenLineCol)
        if isinstance(childNodes, (list, tuple)):
            if newChild is not childNodes[idx]:
                childNodes[idx] = newChild
        else:
            if newChild is not childNodes:
                setattr(astNode, field, newChild)
    # Add the parens that are attached to this node to the unmatched lists from the child
    # nodes, and decide whether astNode needs to be surrounded by parens.
    if isinstance(astNode, (ast.FunctionDef, ast.ClassDef)):
        # Block-owning statements, unfortunately, do not provide usable end_lineno or
        # end_col_offset fields, because the Python parser includes the entire block.
        # This means we can't recover paren data annotation for the no-argument case of
        # function and class definitions.  Luckily, these are also top-level statements,
        # and the parser will not allow users to surround them in parens, anyhow.  It
        # only matters in that it ruins the chance to verify the attribution process by
        # comparing the number of parens attributed to AST nodes with the number found
        # by _extractTokens.
        return None, None, None
    elif isinstance(astNode, ast.Call):
        # Open parens surrounding the call will start before the function name (and
        # thus the starting row/col of the AST), but the parens of the call itself will
        # either be associated with its arguments and assigned in the code above, or
        # (in the no-arg case), with the end paren of the function.
        # Look for left and right parens associated with the position of the right paren
        # of the call (which should happen only in the case where the call has no args)
        noArgLParenList = _getNotAllocated(posToLParen, astNode.end_lineno,
            astNode.end_col_offset-1, allocated)
        noArgRParenList = _getNotAllocated(posToRParen, astNode.end_lineno,
            astNode.end_col_offset-1, allocated)
        if ownParensRemoved:
            if len(noArgLParenList) != 0:
                print('_annotateUserParens associated multiple paren with Call node')
        elif len(noArgRParenList) > 0 and len(noArgLParenList) > 0:
            if len(noArgLParenList) != 1:
                print('_annotateUserParens associated multiple paren with Call node')
            elif len(noArgRParenList) < 1:
                print('_annotateUserParens did not find matching number of parens '
                    'surrounding Call node')
            elif noArgLParenList[0] != noArgRParenList[0]:
                print('_annotateUserParens failed to match parens around call node')
            else:
                # Found matching call parens in no-arg case: claim the paren pair
                if unmatchedRParens is not None and len(unmatchedRParens) > 0:
                    print('_annotateUserParens in unexpected (simultaneous multi-arg and '
                        'no-arg states)')
                allocated.add(noArgRParenList[0])
                unmatchedRParens = [p for p in noArgRParenList if p != noArgRParenList[0]]
        # Get the unmatched left parens associated with the function name (We don't
        # propagate unmatched left parens associated with the args, because they can't
        # surround the function as the function name is in between (if that happened,
        # we've already printed an error)
        unmatchedLParens = _getNotAllocated(posToLParen, astNode.lineno,
            astNode.col_offset, allocated)
    elif isinstance(astNode, ast.Tuple):
        # For both an empty tuple and a single-element tuple, the right paren will be
        # associated with the left edge of the close-paren.  For an empty tuple, the
        # left paren will also be associated with the left edge of the close paren.
        # For multi-element tuples, the line/col position of the tuple itself is
        # irrelevant, because the parens will be associated with the content.
        # Optional tuple parens are represented by setting an attribute on the tuple AST
        # node telling the icon creation function to create an explicit tuple icon rather
        # than splitting the tuple elements across the icon's series sites.
        if ownParensRemoved:
            astNode.tupleHasParens = True
        noArgLParenList = _getNotAllocated(posToLParen, astNode.end_lineno,
            astNode.end_col_offset-1, allocated)
        if len(noArgLParenList) > 0:
            unmatchedLParens = noArgLParenList + unmatchedLParens
        noArgRParenList = _getNotAllocated(posToRParen, astNode.end_lineno,
            astNode.end_col_offset-1, allocated)
        if len(noArgRParenList) > 0:
            unmatchedRParens = unmatchedRParens + noArgRParenList
        if not ownParensRemoved and len(unmatchedLParens) > 0 and \
                len(unmatchedRParens) > 0:
            if unmatchedLParens[-1] != unmatchedRParens[0]:
                print('_annotateUserParens found un-matched parens around tuple')
                return None, None, None
            match = unmatchedLParens[-1]
            allocated.add(match)
            unmatchedLParens = [p for p in unmatchedLParens if p != match]
            unmatchedRParens = [p for p in unmatchedRParens if p != match]
            astNode.tupleHasParens = True
    elif isinstance(astNode, ast.Expr):
        # Technically, the tuple creation code could use the 'tupleHasParens' property to
        # decide to create a naked tuple.  We take the extra step of labeling it with
        # 'isNakedTuple' to ensure that a mislabeled paren won't cause us to accidentally
        # create one somewhere other than the top level.
        if isinstance(astNode.value, ast.Tuple):
            if not hasattr(astNode.value, 'tupleHasParens'):
                astNode.value.isNakedTuple = True
    elif icon.astCreationFunctions.get(astNode.__class__) is not None:
        # For remaining icons, look up associated parens via line/col offset of the start
        # and end.  This will result in lots of duplication (for any icons with coincident
        # sites), but since this works recursively bottom to top, we mark everything
        # that's already been accounted for in the 'allocated' set and don't use it
        # again.  Also note (above) that we skip over nodes that don't have an associated
        # icon creation function, which is a cheap way to eliminate intermediate AST
        # structures that don't become icons.
        if hasattr(astNode, 'col_offset'):
            unmatchedLParens += _getNotAllocated(posToLParen, astNode.lineno,
                astNode.col_offset, allocated)
            unmatchedRParens += _getNotAllocated(posToRParen, astNode.end_lineno,
                astNode.end_col_offset, allocated)
    # Determine if user parens need to be reinserted around the node
    parensNeeded = []
    while len(unmatchedLParens) > 0 and len(unmatchedRParens) > 0:
        match = unmatchedLParens[-1]
        if match != unmatchedRParens[0]:
            print('Paren matching failure in _annotateUserParens',
                  astNode.__class__.__name__, 'line',
                  astNode.lineno if hasattr(astNode, 'lineno') else "none")
            return None, None, None
        unmatchedLParens = [p for p in unmatchedLParens if p != match]
        unmatchedRParens = [p for p in unmatchedRParens if p != match]
        allocated.add(match)
        parensNeeded.append(match)
    return unmatchedLParens, unmatchedRParens, parensNeeded

def _getNotAllocated(annDict, line, col, allocated):
    parenPosList = annDict.get((line, col))
    if parenPosList is None:
        return []
    return [parenPos for parenPos in parenPosList if parenPos not in allocated]

def _commentLinesBetween(lineToCommentMap, startLine, endLine):
    commentList = None
    for lineNum in range(startLine, endLine):
        if lineNum not in lineToCommentMap:
            continue
        if commentList is None:
            commentList = []
        commentList.append(lineNum)
    return commentList

def _commentLinesAfter(lineToCommentMap, startLine):
    commentList = None
    for key, value in lineToCommentMap.items():
        if key < startLine:
            continue
        if commentList is None:
            commentList = []
        commentList.append(key)
    return commentList

def _findClauseBetween(clauseMap, startLine, endLine):
    for line in range(startLine, endLine):
        if line in clauseMap:
            return line, clauseMap[line]
    return None, None

def _outermostAstOnLine(lineNum, exprAst):
    if hasattr(exprAst, 'body'):
        # We can't iterate over children with ast.iter_child_nodes, so just give up
        return None
    if hasattr(exprAst, 'lineno') and hasattr(exprAst, 'end_lineno') and \
            exprAst.lineno == lineNum and exprAst.end_lineno == lineNum:
        return exprAst
    else:
        for a in ast.iter_child_nodes(exprAst):
            outerAst = _outermostAstOnLine(lineNum, a)
            if outerAst is not None:
                return outerAst
    return None

class SegmentedText:
    """Holds save/clipboard .pyg text for an individual python statement, annotated with
    potential line breaks and their associated "level" in the hierarchy of the statement.
    Once collected, the wrapText method will produce an attractively (and compactly)
    wrapped version of the text."""
    __slots__ = ('segments', 'stmtComment')
    # Format for "segments" list is strings separated by numbers (break values).  break
    # values encapsulate the break "level", as well as how the break needs to be made
    # (with/without line continuation and string splitting).  Strings represent text to
    # be added to the file/clipboard, but can also be an object of class QuotedString
    # representing Python strings that can be internally wrapped if necessary.
    #
    # Break values are coded as: breakLevel * 100 + breakType.  The weird base-10 coding
    # is simply to make the values more human-readable (last two digits are type).
    # breakType is a value from 0 to 99 from the table below (needs-continue means that
    # if the code is wrapped, the line must end with a backslash (\) character):
    #   Code:
    #       00: code                    01: code needs-continue
    #   Single quoted strings:
    #       Ones digit is string type:
    #           0 = none, 1 = f, 2 = b, 3 = u, 4 = r, 5 = fr, 6 = br
    #       Tens digit combines quote type and needs-continue:
    #           10 = Single-quote string not needing continue
    #           20 = Double-quote string not needing continue
    #           30 = Single-quote string needing continue
    #           40 = Double-quote string needing continue
    #   Triple quoted strings:
    #       50 = Newline break (mandatory) with dedent to left margin
    #       51 = Non-newline (optional) break needing backslash escape with dedent to
    #            left margin
    #       52 = Newline break (mandatory) without dedent to left margin (help strings)
    #       53 = Non-newline break without dedent to left margin (help strings)

    def __init__(self, initialString=None):
        """Create a SegmentedText object.  initialString may be set to None or an empty
        string, to create an empty string, or to a normal text string.  It may also be
        set to a list of strings, and multiStringBreakLevel specified to initialize it
        to a series of strings punctuated with break-points of the specified level."""
        if initialString is None or initialString == "":
            self.segments = None
        else:
            self.segments = [initialString]
        self.stmtComment = None

    def add(self, breakLevel, text, needsContinue=False):
        """Append a single string to the end of the accumulated text.  If breakLevel
        is set to None, it will be appended directly to the last element of the text,
        without adding a break-point.  If breakLevel is specified as a number, the new
        text will be separated from the existing text by a break-point of that depth.
        Levels (depth values) start at low numbers (which confusingly mean higher levels
        in the hierarchy of the code) and increase with depth.  If needsContinue is
        specified as True, if the break-point is used, a continuation character '\'
        will be added at the end of the line, before the newline."""
        if self.segments is None:
            self.segments = [text]
        elif breakLevel is None:
            prevString = self.segments[-1]
            if type(prevString) is QuotedString:
                prevString.append(text)
            else:
                self.segments[-1] = prevString + text
        else:
            breakValue = _encodeBreakValue(breakLevel, 1 if needsContinue else 0)
            self.segments.append(breakValue)
            self.segments.append(text)

    def wrapCtxMacro(self, breakLevel, parseCtx=None, parentCtx=None, needsCont=False):
        """Surround the segmented text string with a context macro ($Ctx($  $)$) with the
        given parse context (defaults to expression).  Also checks that the existing
        string is not an $Empty$ macro or already surrounded in a context macro. Checking
        for doubling up, here, makes it easier for the calling code, since some context
        needs are determined by the parent icon (such as a name or target context), and
        some are determined by the child icon ("as", keyword assignment, dictionary
        element).  Note that this method requires that the SegmentedText object be non-
        empty and that breakLevel be numeric (as opposed to None), as neither of these
        would be desirable for a $Ctx$ macro.  Also note that if there is an existing
        context macro, the parse context will not be changed (as the only way Ctx macros
        would normally end up stacked is if the bottom one was imposed by the argument
        icon and the top one by the parent icon whose field might be constrained to a
        name or target).  The caller should pass appropriate breakLevels (as if the $Ctx$
        macro will be wrapped), and the function will adjust (reduce) the break level of
        the existing SegmentedText object if it does *not* wrap a new macro."""
        if len(self.segments) == 1 and self.segments[0] == '$Empty$':
            if parentCtx is not None:
                self.segments[0] = '$Empty:%s$' % parentCtx
            return
        elif self._isSingleCtxMacro():
            # Existing context macro.  Update with possible new parent context, but do
            # not wrap a new macro around.  Reduce the break level of the existing text.
            if parentCtx is not None:
                if self.segments[0][4] == ':':
                    self.segments[0] = '$Ctx:' + parentCtx + self.segments[0][5:]
                else:
                    self.segments[0] = '$Ctx:' + parentCtx + self.segments[0][3:]
            for i in range(1, len(self.segments), 2):
                self.segments[i] -= 100
            return
        if parseCtx is None and parentCtx is None:
            ctxMacro = '$Ctx($'
        else:
            ctxMacro = '$Ctx:%s%s($' % ('' if parentCtx is None else parentCtx,
                '' if parseCtx is None else parseCtx)
        breakValue = _encodeBreakValue(breakLevel, 1 if needsCont else 0)
        self.segments[:0] = [ctxMacro, breakValue]
        self.segments += [breakValue, '$)$']

    def wrapFragmentMacro(self, breakLevel, parseCtx, needsCont=False):
        """Surround the segmented text string with a fragment macro ($Fragment($  $)$)
        with the given parse context.  The caller is expected to have set the breakLevel
        for the text to be surrounded, with the expectation that another level will be
        added.  The $Fragment$ macro represents a free fragment that cannot be attached
        to either an input or sequence site, so can only ever appear by itself (whereas a
        $Ctx$ macro adapts the enclosed site to be included in such a context. $Fragment$
        macros never actually make it to the save file, but are instead intercepted by
        the code generating it and merged into the @ macro"""
        fragMacro = '$Fragment:%s($' % parseCtx
        breakValue = _encodeBreakValue(breakLevel, 1 if needsCont else 0)
        self.segments[:0] = [fragMacro, breakValue]
        self.segments += [breakValue, '$)$']

    def concat(self, breakLevel, otherSegText, needsContinue=False):
        """Append another SegmentedText object to the end of the accumulated text.  If
        breakLevel is set to None, it will merge the first element of the appended
        text with the last element of the text, without inserting a break-point between
        them. If breakLevel is specified as a number, the new text will be separated from
        the existing text by a break-point of that depth.  Levels (depth values) start at
        low numbers (which confusingly mean higher levels in the hierarchy of the code)
        and increase with depth.  If needsContinue is specified as True, if the break-
        point is used, a continuation character '\' will be added at the end of the line,
        before the newline."""
        if otherSegText.segments is None:
            return
        if self.segments is None:
            self.segments = otherSegText.segments[:]
        elif breakLevel is None:
            prevString = self.segments[-1]
            firstSeg = otherSegText.segments[0]
            if type(prevString) is QuotedString:
                if type(firstSeg) is QuotedString:
                    raise ValueError("Concatenating quoted strings not supported")
                prevString.append(firstSeg)
            elif type(firstSeg) is QuotedString:
                firstSeg.prepend(prevString)
                self.segments[-1] = firstSeg
            else:
                self.segments[-1] = prevString + otherSegText.segments[0]
            self.segments += otherSegText.segments[1:]
        else:
            breakValue = _encodeBreakValue(breakLevel, 1 if needsContinue else 0)
            self.segments.append(breakValue)
            self.segments += otherSegText.segments

    def addQuotedString(self, breakLevel, strType, strQuote, strContent, isDocString,
            needsContinue, stringBreakLevel=None):
        """Append a (single or double) quoted Python string or f-string to the accumulated
        text.  Like the "add" and "concat" methods, breakLevel may be specified as None
        to add without allowing a line break from the previous text segment.  However, if
        breakLevel is specified as None, stringBreakLevel (which would otherwise default
        to breakLevel + 1) must be specified.  Strings may not be concatenated to each
        other without a wrap point in between.  Specify isDocString for the special case
        of a triple-quote string whose continuation should not be dedented back to the
        left margin (currently, only Python help strings, but might be a worthwhile icon
        option for later)."""
        if stringBreakLevel is None:
            if breakLevel is None:
                raise ValueError("SegmentedText.addQuotedString with breakLevel = None "
                    "requires stringBreakLevel argument specified")
            stringBreakLevel = breakLevel + 1
        qs = QuotedString(strType, strQuote, strContent, isDocString, stringBreakLevel,
            needsContinue)
        if self.segments is None:
            self.segments = [qs]
            return
        if breakLevel is None:
            # Merge with last segment in list
            if type(self.segments[-1]) is QuotedString:
                raise ValueError("Concatenating quoted strings not supported")
            else:
                qs.prepend(self.segments[-1])
                self.segments[-1] = qs
        else:
            # Compute and append break value, followed by QuotedString object
            self.segments.append(_encodeBreakValue(breakLevel, 1 if needsContinue else 0))
            self.segments.append(qs)

    def addComment(self, comment, isStmtComment=False, annotation=None):
        """Add the content of a comment to the text.  Comment can be either in the form
        of a string, or a SegmentedText object holding the comment."""
        # Unlike strings, comments don't need to be integrated in to code wrapping, since
        # they can only be appended to the end of a statement.  Simply add placeholder to
        # preserve space for comment continuation and macro annotation, and record the
        # comment to be wrapped as a post-processing step.
        if isinstance(comment, SegmentedText):
            self.stmtComment = comment.stmtComment
        else:
            self.stmtComment = SegTextComment(comment, isStmtComment, annotation)
        if isStmtComment:
            macro = '' if self.stmtComment.macro is None else self.stmtComment.macro
            self.add(None, '  ' + macro + '# \\', needsContinue=False)

    def copy(self):
        """Segmented text is mutable, and it used in python-g with a less-than-rigorous
        assumption that if code returns a SegmentedText object, it is fair game to
        tack more on to it.  If you want to make sure one won't get extended, use this
        to create a shallow copy to return."""
        st = SegmentedText()
        st.segments = self.segments[:]

    def wrapText(self, startIndent, continuationIndent, margin=100, export=False):
        """Apply wrapping to the collected text.  Unlike a normal Python pretty-printer,
        compactness is favored over prettiness, so if lines can be saved by doing ugly
        wrapping, it will sometimes wrap in a less-ideal place."""
        # The method of wrapping is to first wrap stupidly at whatever wrap points will
        # pack the text the tightest.  This establishes a baseline for how few lines
        # the text can fit.  Once that is known, attempt to improve the appearance by
        # limiting wrapping to higher levels.  When the "tight" line count is exceeded,
        # choose the highest level wrapping that fit in the same number of lines.
        # While globally limiting the wrap-level works well for most Python statements,
        # it can be "fooled" by statements with multiple deeply-nested parts whose depth
        # is inconsistent, because the deep parts prevent good wraps to shallower ones
        # from ever being explored.
        if self.segments is None and self.stmtComment:
            return self.stmtComment.wrap(startIndent, margin, export=export)
        if self.segments is None:
            return ''  # Vertical blank icons are empty and should not generate indent
        maxDepth = 0
        brkLvl = 0
        for s in self.segments:
            if type(s) is int:
                brkLvl, brkType = _decodeBreakValue(s)
                maxDepth = max(maxDepth, brkLvl)
            elif type(s) is QuotedString:
                maxDepth = max(maxDepth, brkLvl + 1)  # A string can be further broken
        # Remove QuotedString objects representing breakable strings, and (if necessary),
        # break them down at word boundaries
        self._breakStrings(startIndent, continuationIndent, margin)
        # Baseline with no level cutoff
        breakPointList = self._findAllBreakPoints(maxDepth + 1, startIndent,
            continuationIndent, margin)
        minLines = len(breakPointList) + 1
        # Improve by attempting to decrement level cutoff
        if minLines > 1:
            for levelCutoff in range(maxDepth, 1, -1):
                levelBPs = self._findAllBreakPoints(levelCutoff, startIndent,
                    continuationIndent, margin)
                nLines = len(levelBPs) + 1
                if nLines > minLines:
                    break
                breakPointList = levelBPs
        # Use the computed break point list to build the string
        startIdx = 0
        strings = [' ' * startIndent]
        for bp in breakPointList:
            breakLevel, breakType = _decodeBreakValue(self.segments[bp])
            # Copy the strings before the breakpoint to strings
            for i in range(startIdx, bp, 2):
                strings.append(self.segments[i])
            # If continuation and/or string splitting is needed, add it
            endChar = None if len(strings) == 0 or len(strings[-1]) == 0 \
                else strings[-1][-1]
            strings.append(_breakPrefix(breakType, endChar))
            # Append the newline and continuation indent (triple quoted strings get
            # no indent, unless they are docstrings, which get startIndent)
            strings.append('\n')
            if breakType < 50:
                strings.append(' ' * continuationIndent)
            elif breakType in (52, 53):
                strings.append(' ' * startIndent)
            # If string continuation was used, restart the string
            strings.append(_breakSuffix(breakType))
            startIdx = bp + 1
        # Copy the text after the last break point
        for i in range(startIdx, len(self.segments), 2):
            strings.append(self.segments[i])
        joinedString = "".join(strings)
        # If there's a statement comment, wrap it and add it to the end of the completed
        # string
        if self.stmtComment:
            return self.stmtComment.wrap(continuationIndent +  STMT_COMMENT_INDENT,
                margin, appendToStmt=joinedString, export=export)
        return joinedString

    def _findAllBreakPoints(self, levelCutoff, startIndent, continueIndent, margin):
        startIdx = 0
        tempTripleQuoteDedent = 0
        continueIndentAdded = False
        breakPoints = []
        while True:
            breakPoint = self._findBreakPoint(startIdx, levelCutoff,
                startIndent - tempTripleQuoteDedent, margin)
            if breakPoint is None:
                break
            breakPoints.append(breakPoint)
            startIdx = breakPoint + 1
            _breakLvl, breakType = _decodeBreakValue(self.segments[breakPoint])
            if not continueIndentAdded:
                startIndent = continueIndent
                startIndent += len(_breakSuffix(breakType))
                continueIndentAdded = True
            if breakType in (50, 51):
                tempTripleQuoteDedent = startIndent
            else:
                tempTripleQuoteDedent = 0
        return breakPoints

    def _findBreakPoint(self, startIdx, levelCutoff, startIndent, margin):
        """ Find the last point where the string can be broken before the given margin"""
        lastAcceptableBreakPoint = startIdx + 1
        if lastAcceptableBreakPoint >= len(self.segments):
            return None
        textWidth = startIndent
        for i in range(startIdx, len(self.segments), 2):
            string = self.segments[i]
            if i+1 < len(self.segments) and _decodeBreakValue(self.segments[i+1])[1] > 1:
                # For strings, trailing spaces are part of the data (don't lop them off).
                lastCharIsSpace = False
            else:
                lastCharIsSpace = string[-1] == ' '
            stringRequiredWidth = len(string) - (1 if lastCharIsSpace else 0)
            if i+1 >= len(self.segments):
                # We reached the end of the statement and it either fits or does not
                if textWidth + stringRequiredWidth <= margin:
                    return None
                else:
                    return lastAcceptableBreakPoint
            breakLevel, breakType = _decodeBreakValue(self.segments[i + 1])
            if breakLevel < levelCutoff:
                endChar = None if len(self.segments[i]) == 0 else self.segments[i][-1]
                stringRequiredWidth += len(_breakPrefix(breakType, endChar))
                if textWidth + stringRequiredWidth > margin:
                    return lastAcceptableBreakPoint
                lastAcceptableBreakPoint = i + 1
            if breakType in (50, 52):  # Mandatory break at newline
                return i + 1
            textWidth += len(string)
        return None  # Because of odd length of segList, this will not be reached

    def _breakStrings(self, startIndent, continueIndent, margin):
        """Measure the length of the text, and if it exceeds what will fit within the
        given parameters (margin - continueIndent for most things), break quoted string
        objects at word boundaries (and non-word boundaries based on on the calculated
        maximum length.  Triple-quoted strings break the rules, in that their indent for
        continuation is either all the way to the left margin, or to startIndent instead
        of continueIndent for doc-strings."""
        totalLength = 0
        for entry in self.segments:
            if type(entry) is not int:
                totalLength += len(entry)
        fitsOnLine = totalLength < margin - startIndent
        # Break strings at word boundaries (or as necessary to fit within maxLength)
        newSegments = []
        for entry in self.segments:
            if isinstance(entry, QuotedString):
                newSegments += entry.breakString(startIndent, continueIndent,
                    margin, fitsOnLine)
            else:
                newSegments.append(entry)
        self.segments = newSegments

    def isFragmentMacro(self):
        """Returns True if the content of the string is a $Fragment$ macro."""
        if self.segments is None or len(self.segments) == 0 or \
                not isinstance(self.segments[0], str):
            return False
        return self.segments[0][:10] == '$Fragment:'

    def isCtxMacro(self):
        """Returns True if the content of the string is a single $Ctx$ macro."""
        if self.segments is None or len(self.segments) == 0 or \
                not isinstance(self.segments[0], str):
            return False
        return self._isSingleCtxMacro()

    def cvtCtxOrFragmentToPosMacro(self, x, y):
        """Convert the $Ctx$ or $Fragment$ macro contained in the string to an $@$ macro
        with the given x,y location (assumes that the caller has verified the content
        with isCtxMacro and/or isFragmentMacro before calling)."""
        posPrefix = "$@%+d%+d:" % (x, y)
        if self.segments[0][:5] == '$Ctx:':
            self.segments[0] = posPrefix + self.segments[0][5:]
        elif self.segments[0][:10] == '$Fragment:':
            self.segments[0] = posPrefix + self.segments[0][10:]
        else:
            print('cvtCtxOrFragmentToPosMacro passed string with unexpected prefix')

    def _isSingleCtxMacro(self):
        """Return True if the entire contents of the object is a single $Ctx$ macro.
        Unfortunately, it is not as simple as checking for $Ctx at the start and $)$ at
        the end, because of the annoying possibility of a binary operator with a $Ctx
        macro as its right operand and another argument-containing macro as its right
        argument."""
        if not ctxMacroPattern.match(self.segments[0]) or self.segments[-1][-3:] != '$)$':
            return False
        # The segmented text string begins with $Ctx and ends with $)$, but we still need
        # to show that the paren level does not reach 0 before the end of the string.
        # If it does, this is not a single macro.  Note that we're not bothering to parse
        # inside of the segments, as theoretically a single segment should not contain
        # both open and close parens.  If there are multiple paren types within a segment
        # or the paren level does not return to 0 at the end, we simply return False, as
        # the only consequence of being wrong is an unnecessary nested $Ctx$ macro.
        macroParenLevel = 0
        for i in range(0, len(self.segments), 2):
            seg = self.segments[i]
            if isinstance(seg, QuotedString):
                # Skip quoted strings that could contain text that mimics macro parens
                continue
            numMacroOpenParens = seg.count('($')
            numMacroCloseParens = seg.count('$)')
            if numMacroOpenParens > 0 and numMacroCloseParens > 0:
                # This shouldn't happen and is too complex to deal with if it does
                return False
            macroParenLevel += numMacroOpenParens
            macroParenLevel -= numMacroCloseParens
            if macroParenLevel == 0:
                if i == len(self.segments) - 1:
                    return True
                return False
        return False

class QuotedString:
    """Helper object for SegmentedText to hold Python quoted strings.  Strings are
    distinct from other code objects in that they are internally wrappable.  They are
    held in unwrapped form, until it is known whether the line will need wrapping at
    all.  If the line needs no wrapping, the string can be returned returned as-is using
    the unbrokenString method.  If the line will need wrapping, the breakString method
    will split it at word boundaries (and based on maxLength, within word boundaries
    if any of the remaining "words" exceed that limit).  breakString returns the split
    string in SegmentedText's "segments" format, so the SegmentedText wrapText method
    can wrap the string along with everything else it's wrapping."""
    __slots__ = ('strType', 'quote', 'text', 'breakLevel', 'breakType', 'prependedText',
        'appendedText')

    def __init__(self, strType, strQuote, text, isDocString, brkLvl, needsCont):
        self.breakType = _encodeStringBreakType(strType, strQuote, isDocString, needsCont)
        self.strType = strType
        self.quote = strQuote
        self.text = text
        self.breakLevel = brkLvl
        self.prependedText = ""
        self.appendedText = ""

    def __len__(self):
        """Return the length of the quoted string (including quotes) assuming no
        line breaks are added."""
        return len(self.strType) + 2 * len(self.quote) + len(self.text) + \
            len(self.prependedText) + len(self.appendedText)

    def breakString(self, startIndent, continueIndent, margin, fitsOnLine):
        """Split the string at the end of whitespace of word boundaries, and return a
        SegmentedText.segments-style list that can be spliced-in in place of the
        QuotedString object in the list.  Strings longer than will fit between the
        given indents and margin are also split, even if they don't have whitespace.
        The maximum length depends upon the string type and whether it is the initial
        or subsequent portion of the string (triple-quoted strings dedent either back
        to the left margin, or to startIndent if they are doc-strings).  Set fitsOnLine
        to True to save work if the stated (by len()) total length of the string will fit
        on the line, but we may still break the line, if it is a doc-string containing
        one or more newline characters, since that will need reindenting by the caller."""
        if fitsOnLine and self.breakType != 53 or (self.breakType == 53 and
                '\n' not in self.text):
            return [self.unbrokenString()]
        foundSpace = False
        segmentStrings = []
        startIdx = 0
        stringStart = self.prependedText + self.strType + self.quote
        maxFirstSegLen = max(margin - continueIndent, len(stringStart) + 1)
        for i, c in enumerate(self.text):
            if c == '\n':
                segmentStrings.append(stringStart + self.text[startIdx:i+1])
                stringStart = ""
                startIdx = i+1
                foundSpace = False
            elif c.isspace():
                foundSpace = True
            elif foundSpace:
                segmentStrings.append(stringStart + self.text[startIdx:i])
                stringStart = ""
                startIdx = i
                foundSpace = False
        segmentStrings.append(stringStart + self.text[startIdx:] + self.quote +
            self.appendedText)
        # Adjust maxLength for continuation characters needed, to a minimum of 5
        # characters (at that point we give up and exceed the requested margin),
        # and for triple quotes which dedent all the way to the left margin.
        if self.breakType == 51:
            maxLength = margin
        elif self.breakType == 53:
            maxLength = margin - startIndent
        else:
            maxLength = margin - continueIndent
        maxLength -= len(_breakPrefix(self.breakType)) + \
                     len(_breakSuffix(self.breakType))
        if maxLength < 5:
            maxLength = 5
        # add breakValue between segments, and if any segments are still longer than
        # maxLength, break those, further
        segments = []
        brkValue = _encodeBreakValue(self.breakLevel, self.breakType)
        for i, string in enumerate(segmentStrings):
            maxSegLength = maxFirstSegLen if i == 0 else maxLength
            if len(string) > maxSegLength:
                startIdx = 0
                while len(string) - startIdx > maxSegLength:
                    segments.append(string[startIdx:startIdx + maxSegLength])
                    segments.append(brkValue)
                    startIdx += maxSegLength
                segments.append(string[startIdx:])
            else:
                segments.append(string)
            if i < len(segmentStrings) - 1:
                if segments[-1][-1] == '\n':
                    # Triple quoted string line ending: strip off newline and add a
                    # mandatory break (type 50 or 53)
                    segments[-1] = segments[-1][:-1]
                    segments.append(self.breakType - 1)
                else:
                    segments.append(brkValue)
        return segments

    def unbrokenString(self):
        return self.prependedText + self.strType + self.quote + self.text + self.quote + \
               self.appendedText

    def append(self, text):
        self.appendedText += text

    def prepend(self, text):
        self.prependedText = text + self.prependedText

class SegTextComment:
    """Helper object for SegmentedText to hold comments and their related settings."""
    __slots__ = ('text', 'macro')
    def __init__(self, text, isStmtComment=False, annotation=None):
        if isStmtComment:
            self.text = text.replace('\n', '\\n')
        else:
            self.text = text
        self.macro = None if annotation is None else ('$:' + annotation + '$')

    def wrap(self, indent, margin, appendToStmt=None, export=False):
        """Wraps comment text, indenting to indent and wrapping at margin.  Optionally,
        (if appendToStmt is not None) append comment text to an (already processed into
        string form) statement."""
        # Wrap the text of the comment at the margin, adding extra newlines where
        # marked with hard newlines.  The textwrap module almost does what we want,
        # except for its handling of embedded newlines, so we can only use it
        # per-newline-terminated-line rather than on all of the lines together.
        indentString = (indent * " ")  + "# "
        lineWrapMargin = margin - (indent + 3)
        if appendToStmt is None and self.macro is None:
            firstLineWrapMargin = lineWrapMargin
        else:
            if appendToStmt is None and self.macro is not None:
                appendToStmt = (indent * " ") + self.macro + '# \\'
            elif len(appendToStmt) < 5 or appendToStmt[-5:] != '  # \\':
                print('SegTextComment did not find expected placeholder in stmt text')
                appendToStmt += '  # \\'
            index = appendToStmt.rfind('\n')
            if index == -1:
                index = 0
            firstLineWrapMargin = margin - (len(appendToStmt) - index)
        origLines = self.text.split("\n")
        if not export:
            escapeLineContinuations(origLines)
        continueWrap = '\\\n' + indentString
        nonContinueWrap = '\n' + indentString
        wrappedLines = []
        perLineMargin = firstLineWrapMargin
        for i, line in enumerate(origLines):
            if len(line) <= perLineMargin + 1:
                # If the line does not need to be wrapped, save work and gain one
                # additional space without continuation character.
                wrappedLine = line
            else:
                words = comn.splitWords(line)
                wrappedLine = continueWrap.join(comn.wordWrap(words, lineWrapMargin,
                    firstLineMax=perLineMargin, lastLineMax=lineWrapMargin+1))
            perLineMargin = lineWrapMargin
            wrappedLines.append(wrappedLine)
        outText = nonContinueWrap.join(wrappedLines)
        if appendToStmt is not None:
            return appendToStmt[:-1] + outText
        return indentString + outText

def _decodeBreakValue(breakValue):
    brkLevel = breakValue // 100
    brkType = breakValue - brkLevel * 100
    return brkLevel, brkType

def _encodeBreakValue(breakLevel, breakType):
    return breakLevel * 100 + breakType

def _encodeStringBreakType(strType, quote, isDocString, needsContinue):
    if len(quote) == 1:
        typeDigit = {'': 0, 'f': 1, 'b': 2, 'u': 3, 'r': 4, 'fr': 5, 'br': 6, 'rf': 5,
            'rb': 6}[strType]
        quoteContDigit = {"'": 10, '"': 20}[quote] + (20 if needsContinue else 0)
        return typeDigit + quoteContDigit
    # For triple quoted strings, string and quote types and need for continuation are not
    # encoded in the break type, since we don't have to restart the string after a wrap.
    if isDocString:
        return 53
    return 51

def _decodeStringBreakType(breakType):
    quoteContDigit = breakType // 10
    if quoteContDigit == 5:
        return None, '"""', None
    typeDigit = breakType - quoteContDigit * 10
    strType = {0:'', 1:'f', 2:'b', 3:'u', 4:'r', 5:'fr', 6:'br'}[typeDigit]
    quote = "'" if quoteContDigit in (1, 3) else '"'
    needsCont = quoteContDigit in (3, 4)
    return strType, quote, needsCont

def _breakPrefix(breakValue, endChar=None):
    """Return the appropriate line ending for a given break value.  Note that endChar is
    only used for code breaks (breakValue==1) to determine whether to add or not add an
    additional space before the backslash, and so not needed for string break types."""
    breakLvl, breakType = _decodeBreakValue(breakValue)
    if breakType < 10:
        if breakType == 0:
            return ''
        elif endChar == ' ':
            return '\\'
        return ' \\'
    if breakType in (50, 52):
        return ''
    if breakType in (51, 53):
        return '\\'
    if 10 <= breakType <= 49:
        strType, quote, needsCont = _decodeStringBreakType(breakType)
        return quote + (' \\' if needsCont else '')

def _breakSuffix(breakValue):
    breakLvl, breakType = _decodeBreakValue(breakValue)
    if breakType < 10 or breakType >= 50:
        return ''
    strType, quote, needsCont = _decodeStringBreakType(breakType)
    return strType + quote

def moveIconToPos(ic, pos):
    """Move the given icon, ic, such that the site that "officially" designates its
    position (ic.pos()) lies on the specified x, y position, pos."""
    x, y = ic.pos()
    ic.rect = comn.offsetRect(ic.rect, pos[0] - x, pos[1] - y)


class ReprocSyntaxErrExcept(Exception):
    lineNumRe = re.compile('.*(line \\d*\\))')

    def __init__(self, excep, lineNumTranslate=None, originalText=None, ctxMask=None):
        excepMsg = str(excep)
        if lineNumTranslate is None:
            message = "%s: %s" % (excep.__class__.__name__, excepMsg)
        else:
            caretLine = excep.text[:excep.offset-1] + ERR_START_ARROW + \
                excep.text[excep.offset-1:]
            if ctxMask is not None:
                caretLine = caretLine[ctxMask[0]:len(caretLine)-ctxMask[1]]
            origLineNum = lineNumTranslate[excep.lineno - 1]
            origLine = numberedLine(originalText, origLineNum)
            macrosPossible = origLine != excep.text.rstrip('\n')
            lineNumMatch = self.lineNumRe.fullmatch(excepMsg)
            if lineNumMatch:
                message = excepMsg[:lineNumMatch.start(1)] + 'line %d)\n%s' % \
                    (origLineNum, caretLine)
                if macrosPossible:
                    message += "\nExpanded from input file line:\n" + origLine
            else:
                message = "%s\n%s" % (excepMsg, caretLine)
                message += "\nExpanded from input file line %d" % origLineNum
                if macrosPossible:
                    message += ":\n" + origLine
        super().__init__(message)

class MacroFailException(Exception):
    def __init__(self, text, idx, lineNum=None, message=None):
        super().__init__(formatMacroFailMessage(text, idx, lineNum, message))

def formatMacroFailMessage(text, idx, lineNum, message):
    macroEnd = -1
    if message is None:
        macroEnd = text.find('$', idx + 1)
        if macroEnd == -1:
            macro = text[idx:idx + 10] + '...'
        elif macroEnd - idx > 100:
            macro = text[idx:idx + 100] + '...'
        else:
            macroEnd += 1
            macro = text[idx:macroEnd]
        if lineNum is None:
            message = "Unrecognized macro: %s" % macro
        else:
            message = "Unrecognized macro on line %d: %s" % (lineNum, macro)
    else:
        if lineNum is not None:
            message = "%s, line %d" % (message, lineNum)
    for i in range(idx, -1, -1):
        if text[i] == '\n':
            lineStart = i + 1
            break
    else:
        lineStart = 0
    lineEnd = text.find('\n', idx)
    if lineEnd == -1:
        lineEnd = len(text)
    if macroEnd != -1 and macroEnd <= lineEnd:
        message += '\n' + text[lineStart:idx] + ERR_START_ARROW + \
                   text[idx:macroEnd] + ERR_END_ARROW + text[macroEnd:lineEnd]
    else:
        message += '\n' + text[lineStart:idx] + ERR_START_ARROW + text[idx:lineEnd]
    return message

def ctxMacroFn(astNode, macroArgs, argAsts, window):
    if argAsts is None:
        return None
    if macroArgs is not None:
        if 'K' in macroArgs and not isinstance(astNode, ast.keyword):
            return None
        if 'D' in macroArgs:
            # Handled in listicons.createDictIconFromAst, because ast.Dict nodes hold
            # lists of keywords and values (have no concept of a dictionary element)
            return None
    return icon.createFromAst(argAsts[0], window)

def isAttrParseStub(astNode):
    return isinstance(astNode, ast.Name) and astNode.id == ATTR_PARSE_STUB

class DictElemFakeAst:
    def __init__(self, keyAst, valueAst):
        self.key = keyAst
        self.value = valueAst

class ArgAssignFakeAst:
    def __init__(self, keywordAst):
        self.keywordAst = keywordAst

class CprhForFakeAst:
    def __init__(self, target, iter, isAsync):
        self.target = target
        self.iter = iter
        self.isAsync = isAsync

class CprhIfFakeAst:
    def __init__(self, cmp):
        self.cmp = cmp

class RelImportNameFakeAst:
    def __init__(self, moduleName, level):
        self.moduleName = moduleName
        self.level = level

class UserParenFakeAst(ast.AST):
    def __init__(self, argAst, startLineCol):
        # Unlike the other fake asts, this one needs ast.walk to be able to traverse it
        self._fields = ('arg',)
        self.arg = argAst
        self.lineno = startLineCol[0]
        self.col_offset = startLineCol[1]

class CommentFakeAst(ast.AST):
    def __init__(self, annotation, text):
        self.ann = annotation
        self.text = text

def numberedLine(text, lineNum):
    """Return a single line (lineNum) from text.  Note, that this inefficiently scans
    the entire text for newlines to find the specified line."""
    startIdx = 0
    for i in range(lineNum-1):
        startIdx = text.find('\n', startIdx)
        if startIdx == -1:
            return ""
        startIdx += 1
    endIdx = text.find('\n', startIdx)
    if endIdx == -1:
        return text[startIdx:]
    return text[startIdx:endIdx]

def countLinesAndCols(text, endPos, startLine, startCol):
    line = startLine
    col = startCol
    for i, c in enumerate(text):
        if i >= endPos:
            return line, col
        if c == '\n':
            col = 0
            line += 1
        else:
            col += 1
    return line, col

def escapeLineContinuations(lines):
    """Turn trailing backslash on strings in parameter lines to double backslash."""
    for i, line in enumerate(lines):
        if len(line) > 0 and line[-1] == '\\':
            lines[i] += '\\'

def strAt(text, start, str):
    """Safely execute: text[start:start+len(str)] == str when start might be before start
    of text. """
    if start < 0:
        return False
    return text[start:start+len(str)] == str

def _moduleTest():
    macroParser = MacroParser()
    macroParser.addMacro("l1", "", countLinesAndCols)
    macroParser.addMacro("testSubs", '"testing substitution"', numberedLine)
    macroParser.addMacro("testDollar", 'nert.asdf$.wang.thing(wang)')
    macroParser.addMacro("testDollarEnd", "3+$")
    macroParser.addMacro("if", "if a == $2:\n        pass")
    text="""$:v$[a, b, c]
$:for$for i in range(3):
    print(i $:v$+ 1 $:h$* $testDollarEnd$42)
    $testSubs$
    $if:macroifconst$
    print(a$:subscript$[1], $:kwd$end=2)
    a = $:gencomp$(x for x in range(3)), $:dict${a:1, b:2}
    a $:augassign$+= i $:inline if$if i $:is$is 0 else $:unary$-i
    $testDollar$
    $:if$if i $:compare$== 1:
        pass
    $:elif$elif i==2:
        pass
    $:else$else:
        pass
    $l1:
l2$pass
"""
    print('original text:\n%s\n' % text)
    stmtList, _, _ = parseTextToAsts(macroParser, text, 0, 1, 'nurdle.py')
    for stmt in stmtList:
        for node in ast.walk(stmt):
            macroName = macroArgs = iconCreateFn = None
            if hasattr(node, 'macroName'):
                print('annotated node %s with macro name %s' %
                    (node.__class__.__name__, node.macroName))
            if hasattr(node, 'macroArgs'):
                print('annotated node %s with macro args %s' %
                      (node.__class__.__name__, node.macroArgs))
            if hasattr(node, 'iconCreationFunction'):
                print('annotated node %s with icon creation function %s' %
                      (node.__class__.__name__, repr(node.iconCreationFunction)))
        astpretty.pprint(stmt)

def outFormatTest():
    segText = SegmentedText("asdf")
    segText.add(None, "(")
    segText.add(2, "$:w$")
    segText.addQuotedString(None,'fr', '"', 'this is a long string with lots of words '
        'it. I am going to keep typing and typing until I have oooooooooooooooooooooo '
        'something really long and hard to fit within the margin.  Lets do lot\'s of '
        'wrapping!  Here I go, lots more text coming.  Lots of love: xxxxxxxxxxxxxxxx'
        'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', False, True, 2)
    segText.add(2 , ", ")
    segText.addQuotedString(None,'r', '"""',
    """Add a macro to annotate and extend the save-file and pasted-text format beyond
the base Python syntax.  The save-file format extends Python with macros of the
form $name:argString$.  name is composed of the same set of characters as Python
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
identifiers. Macros that skip the name ($:args$) provide (mostly layout-ralated)
information to the built-in icon creation functions for Python itself.  The colon
separates the macro name from its arguments, and may be omitted if there are no
arguments to pass.  The format of the argument string (argString) is entirely up
to the implementer, but must not contain the "$" character.""", False, True, 2)

    segText.add(None, ", ")
    fakeSegText = SegmentedText("deleteme")
    fakeSegText.segments = ["asdf, ",200,"nert(",300, "wang, ",300, "blort), ",201,
        "bbbbb + ", 300, "45 * ", 400, "3) + ", 101, "10 * ", 201, "2 ** ", 301, "4"]
    segText.concat(2, fakeSegText)
    print(repr(segText.segments))
    for margin in range(12, 100, 4):
        print("-"*margin, margin)
        savedSegments = segText.segments[:]  # Wrapping can only be done once
        print(segText.wrapText(4, 8, margin))
        segText.segments = savedSegments
# outFormatTest()
#_moduleTest()