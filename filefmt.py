import ast, astpretty
import re
import io
import tokenize
import textwrap
import numbers
import comn

SINGLE_QUOTE_STRING = 1
DOUBLE_QUOTE_STRING = 2
TRIPLE_SINGLE_QUOTE_STRING = 3
TRIPLE_DOUBLE_QUOTE_STRING = 4

# Additional indent to continue a statement-comment
STMT_COMMENT_INDENT = 4

# Attach per-icon comments as statement comments until display/edit code catches up
NO_ICON_COMMENTS = True

posMacroPattern = re.compile("(([-+])\\d*)(([-+])\\d*)")

class MacroParser:
    macroPattern = re.compile("\\$[^$]+\\$")
    leftArgOpRe = re.compile(
        "\\+|-|/|%|\\*|<|>|\\||\\^|&|is|in|and|or|if|=|!=|\\(|\\.|\\[")

    def __init__(self):
        self.macroList = {'Empty': ('xxx_empty_arg_xxx', lambda n, w: None)}

    def addMacro(self, name, subs="", iconCreateFn=None):
        """Add a macro to annotate and extend the save-file and pasted-text format beyond
        the base Python syntax.  The save-file format extends Python with macros of the
        form $name:argString$.  name is composed of the same set of characters as Python
        identifiers. Macros that skip the name ($:args$) provide (mostly layout-ralated)
        information to the built-in icon creation functions for Python itself.  The colon
        separates the macro name from its arguments, and may be omitted if there are no
        arguments to pass.  The format of the argument string (argString) is entirely up
        to the implementer, but must not contain the "$" character.  The argument, subs,
        provides text to replace the macro before parsing with the Python parser, and
        may alternatively be passed as a function to generate the substitution string
        from the macro argString.  Since the ultimate goal is to create icons, string
        substitution is needed only in rare cases to temporarily support sub-structure
        (such as statement blocks) and get it to pass initial parsing.  Most of the work
        will be done in the icon creation function (iconCreateFn).  Since macros are
        associated with AST nodes based on their location in the save-file, there is
        a special case for nodes generated by text substitution by the macro, itself.
        To reference a python construct inserted by the macro, the substitution text
        should place a '$' character before the item to be marked.  The '$' will be
        removed in the substitution process, and the macro data will be associated
        with the python code that followed it in the inserted text.  iconCreateFn
        should be a function with parameters for astNode and window.  Macro name and
        macro arguments are attached to astNode as properties (macroName, macroArgs)
        (see ... for details)"""
        self.macroList[name] = subs, iconCreateFn

    def expandMacros(self, text):
        """Takes text in python_g clipboard/save-file text format, expands macros and
        returns three items:
            1) The macro-expanded text
            2) An object for looking up macro annotation (name, arguments, and icon
               creation function) given an AST node resulting from parsing the text.
            3) A list whose index is line numbers in the macro-expanded version of the
               text and whose content is the corresponding line number in the original
               text (before expansion)."""
        annotations = AnnotationList()
        lineNumTranslate = []
        origLineStarts = [0]
        origLineNum = 1
        modLineNum = 1
        modColNum = 0
        modTextFrags = []
        modFragStart = 0
        origIdx = 0
        inString = None
        inComment = False
        while origIdx < len(text):
            origChar = text[origIdx]
            if origChar == '\t' and not inComment and inString is None:
                macroFailDialog(text, origIdx, origLineNum, "Tab characters not allowed")
                return None, None, []
            if origChar == '\n':
                inComment = False
                lineNumTranslate.append(origLineNum)
                origLineNum += 1
                modLineNum += 1
                modColNum = 0
                origLineStarts.append(origIdx+1)
                origIdx += 1
            elif origChar == '$' and not inComment and inString is None:
                # Macro found.  Process it and get replacement text
                match = self.macroPattern.match(text, origIdx)
                if match is None:
                    macroFailDialog(text, origIdx, origLineNum)
                    return None, None, []
                macroEndIdx = origIdx + len(match.group(0))
                replaceText = self._processMacro(modLineNum, modColNum, text, origIdx,
                    macroEndIdx, annotations)
                if replaceText is None:
                    macroFailDialog(text, origIdx, origLineNum)
                    return None, None, []
                # Copy the text between the last macro and this one in to the output list
                textToCopy = text[modFragStart:origIdx]
                modTextFrags.append(textToCopy)
                # Copy the macro's replacement text in to the output list
                modTextFrags.append(replaceText)
                # Adjust line counts for newlines in macro or replaced text
                origLineNum += text[origIdx:macroEndIdx].count('\n')
                modLines = replaceText.split('\n')
                for i in range(len(modLines) - 1):
                    modLineNum += 1
                    lineNumTranslate.append(origLineNum)
                if len(modLines) > 1:
                    modColNum = len(modLines[-1])
                else:
                    modColNum += len(replaceText)
                origIdx = macroEndIdx
                modFragStart = origIdx
            else:
                # While some macro languages require full ownership of the macro-
                # introducing character(s), we allow $ characters to appear in strings
                # and comments (the alternative being transforming them to $$ or similar
                # on output).  Therefore, even though we're only looking for macros, we
                # still need to do enough parsing to recognize strings and comments.
                if origChar == '#' and inString is None:
                    inComment = True
                elif origChar == '"' and not inComment:
                    if inString is None:
                        if strAt(text, origIdx-2, '"""'):
                            inString = TRIPLE_DOUBLE_QUOTE_STRING
                        elif inString != SINGLE_QUOTE_STRING:
                            inString = DOUBLE_QUOTE_STRING
                    elif inString == DOUBLE_QUOTE_STRING:
                        if not strAt(text, origIdx-1, '\\"') or \
                                strAt(text, origIdx-2, '\\'):
                            inString = None
                    elif inString == TRIPLE_DOUBLE_QUOTE_STRING:
                        if strAt(text, origIdx-2, '"""'):
                            if not strAt(text, origIdx-3, '"') or \
                                    strAt(text, origIdx-5, '""""""'):
                                inString = None
                elif origChar == "'" and not inComment:
                    if inString is None:
                        if strAt(text, origIdx-2, "'''"):
                            inString = TRIPLE_SINGLE_QUOTE_STRING
                        elif inString != DOUBLE_QUOTE_STRING:
                            inString = SINGLE_QUOTE_STRING
                    elif inString == SINGLE_QUOTE_STRING:
                        if not strAt(text, origIdx-1, "\\'") or \
                                strAt(text, origIdx-2, '\\'):
                            inString = None
                    elif inString == TRIPLE_SINGLE_QUOTE_STRING:
                        if strAt(text, origIdx-2, "'''"):
                            if not strAt(text, origIdx-3,  "'") or \
                                    strAt(text, origIdx-5, "''''''"):
                                inString = None
                # Advance to the next character and increment column count
                modColNum += 1
                origIdx += 1
        # Copy the text between the last macro and the end of the input text to the output
        modTextFrags.append(text[modFragStart:])
        # Consolidate the output fragments in to a single string, and return it and the
        # annotation dictionary and line number translation list
        return "".join(modTextFrags), annotations, lineNumTranslate

    def _processMacro(self, modLineNum, modColNum, origText, macroStartIdx, macroEndIdx,
            annotations):
        """Process a macro in origText between macroStartIdx and macroEndIdx, adding
        entries to annotations object for associating data from the named macro and the
        argument string with appropriate AST node.  Returns text to substitute for the
        macro before passing it on to the Python parser."""
        macroText = origText[macroStartIdx+1:macroEndIdx-1]
        macroName, macroArgs = self._parseMacro(macroText)
        if macroName is None:
            return None
        if macroName == "":
            replaceText = ""
            iconFn = None
        elif macroName == "@":
            replaceText = "pass"
            iconFn = None
        else:
            macroData = self.macroList[macroName]
            if macroData is None:
                return None
            subs, iconFn, = macroData
            if callable(subs):
                replaceText = subs(macroArgs)
            else:
                replaceText = subs
        # Translate the dollar sign marker in the replacement text to an offset
        # and remove it from the text
        astMarker = replaceText.find("$")
        if astMarker == -1:
            astMarker = 0
        elif astMarker == len(replaceText) - 1:
            replaceText = replaceText[:-1]
        else:
            replaceText = replaceText[:astMarker] + replaceText[astMarker + 1:]
        # Associate the line and column of the text that will generate the AST with the
        # macro data we want to attach to it
        adjLine, adjCol = countLinesAndCols(replaceText, astMarker, modLineNum, modColNum)
        annotations.indexByStartPos(adjLine, adjCol, (macroName, macroArgs, iconFn))
        # AST nodes with arguments on the left report line and column of their leftmost
        # argument (not of their own text), which is not useful for corresponding them
        # with the text that generated them.  For binary operations and assignments
        # (and text that looks like one of these, but we can't tell without parsing)
        # record, also, the rightmost position of their left argument
        if astMarker >= len(replaceText):
            # Marked AST is after macro
            isLeftArgOp = self.leftArgOpRe.match(origText, macroEndIdx)
        else:
            # Marked AST is within macro
            isLeftArgOp = self.leftArgOpRe.match(replaceText, astMarker)
        if isLeftArgOp:
            # Look backward from op through the expanded macro text to find the last
            # non-whitespace character
            adjLine, adjCol = self._leftArgLineCol(adjLine, adjCol, replaceText,
                astMarker)
            # If non-white text was not found within the macro replacement text, search
            # before the macro
            if adjLine == -1:
                adjLine, adjCol = self._leftArgLineCol(modLineNum, modColNum, origText,
                    macroStartIdx)
            annotations.indexByLeftArgEnd(adjLine, adjCol, (macroName, macroArgs, iconFn))
        return replaceText

    @staticmethod
    def _leftArgLineCol(modLineNum, modColNum, text, idx):
        """Binary operators and assignments, unfortunately, do not encode the line and
        column of the operator, but of the entire expression.  The code here, marches
        backward from the index where the operator starts (idx) to find the first
        non-white, decrementing modLineNum and modColNum per corresponding newlines and
        whitespace characters found in the string (text).  If no whitespace is found,
        returns -1 for both line and column.  The calling code will index the macro data
        by for the AST using the returned line and column, which will correspond to the
        rightmost character of its left argument."""
        for i in range(idx-1, -1, -1):
            if text[i] == '\n':
                modLineNum -= 1
                for pl in range(i-1, -1, -1):
                    if text[pl] == '\n':
                        prevLineStart = pl + 1
                        break
                else:
                    prevLineStart = 0
                modColNum = i - prevLineStart
            elif text[i] in '\t ':
                modColNum -= 1
            else:
                return modLineNum, modColNum
        return -1, -1

    @staticmethod
    def _parseMacro(macroText):
        """Split a macro into name and argument components and check for legal name.
        macroName returns None on error, and an empty string for legal but unnamed."""
        if macroText[0] == '@':
            # Segment position macro
            return '@', macroText[1:]
        if macroText[0] == ':':
            # Annotation-only for built-in Python syntax
            return "", macroText[1:]
        # Split name from arguments at :
        for i, c in enumerate(macroText):
            if c == ":":
                return macroText[:i], macroText[i+1:]
            if not c.isalnum() and c != '_':
                return None, None
        # No arguments found
        return macroText, None

class AnnotationList:
    """Associate macros with the ast nodes they generated."""
    def __init__(self):
        self.byStartPos = {}
        self.byLeftArgEnd = {}

    def indexByStartPos(self, line, col, annotation):
        self.byStartPos[(line << 16) + col] = annotation

    def indexByLeftArgEnd(self, line, col, annotation):
        self.byLeftArgEnd[(line << 16) + col] = annotation

    def get(self, node):
        leftNode = None
        nodeClass = node.__class__
        if nodeClass is ast.Expr:
            return None  # Expr nodes have the same offset as their content
        if nodeClass in (ast.BinOp, ast.Compare):
            leftNode = node.left
        elif nodeClass is ast.Assign:
            leftNode = node.targets[-1]
        elif nodeClass in (ast.AugAssign, ast.AnnAssign):
            leftNode = node.target
        elif nodeClass is ast.Call:
            leftNode = node.func
        elif nodeClass in (ast.Attribute, ast.Subscript):
            leftNode = node.value
        elif nodeClass is ast.IfExp:
            leftNode = node.body
        if leftNode:
            if hasattr(leftNode, 'end_lineno') and hasattr(leftNode, 'end_col_offset'):
                line = leftNode.end_lineno
                col = leftNode.end_col_offset
                return self.byLeftArgEnd.get((line << 16) + col)
        else:
            if hasattr(node, 'lineno') and hasattr(node, 'col_offset'):
                return self.byStartPos.get((node.lineno << 16) + node.col_offset)
        return None

    def getByLineAndCol(self, line, col):
        return self.byStartPos.get((line << 16) + col)

    def dump(self):
        print("annotations byStartPos")
        for key, val in self.byStartPos.items():
            print("   ", key >> 16, key & 0xffff, repr(val))
        print("annotations byLeftArgEnd")
        for key, val in self.byLeftArgEnd.items():
            print("   ", key >> 16, key & 0xffff, repr(val))

def parseText(macroParser, text, fileName="Pasted Text", forImport=False):
    """Parse save-file format (from clipboard or file) and return a list of tuples
    pairing a window position with a list of AST nodes to form a sequence.  If the
    position is None, the segment should be attached to the window module sequence point.
    On parse failure, posts up a dialog describing the failure and returns None."""
    # Expand macros
    expandedText, annotations, lineNumTranslate = macroParser.expandMacros(text)
    if expandedText is None:
        return None
    #print('expanded Text:\n%s' % expandedText)
    #print('lineNumTranslate', lineNumTranslate)
    #annotations.dump()
    # Parse expanded text
    try:
        modAst = ast.parse(expandedText, fileName)
    except SyntaxError as excep:
        syntaxErrDialog(excep, lineNumTranslate, text)
        return None
    except Exception as excep:
        parseFailDialog(excep)
        return None
    if not isinstance(modAst, ast.Module) or len(modAst.body) == 0:
        print("Unexpected AST returned from ast.parse")
        return None
    # Ast parsing tosses comments, but we need them
    _transferCommentsToAst(expandedText, modAst, annotations, forImport)
    # Annotate the nodes in the tree per the annotations list
    for node in ast.walk(modAst):
        ann = annotations.get(node)
        if ann is not None:
            macroName, macroArgs, iconCreateFn = ann
            if macroName is not None and macroName != "":
                node.macroName = macroName
            if macroArgs is not None:
                node.macroArgs = macroArgs
            if iconCreateFn is not None:
                node.iconCreationFunction = iconCreateFn
    # Split the parse results in to separately positioned segments
    currentSegment = []
    segments = [(None, currentSegment)]
    for node in modAst.body:
        ann = annotations.get(node)
        if ann is not None and ann[0] == "@":
            currentSegment = []
            segments.append((_parsePosMacro(ann[1]), currentSegment))
        else:
            currentSegment.append(node)
    return segments

def _transferCommentsToAst(text, moduleAst, annotations, forImport):
    """Parse comments out of text and annotate the appropriate AST nodes so we can find
    them again when constructing the icon hierarchy from the AST."""
    comments, elses, consts, commentOnlyLines = _extractTokens(text, annotations,
        forImport)
    _annotateAstWithComments(comments, elses, commentOnlyLines, moduleAst.body)
    _annotateAstConsts(consts, moduleAst)

def _extractTokens(text, annotations, forImport):
    """ Return four dictionaries: 1 mapping line numbers to comments, and 2 mapping
    line numbers to else/elif/except/finally statements (the dictionary holds start
    column number), 3 mapping line/col pairs to source strings for strings and numbers,
    and 4 (a set, not a dict) records line numbers of lines that contain only a comment.
    annotations argument is used to attach comment macro annotations, and to know  how to
    interpret line breaks in the column (by interpreting the macro arguments to detect
    "w" argument indicating that the comment should be wrapped)."""
    # While it seems wasteful to run a whole separate pass over the file to extract
    # comments and detect the positioning of else statements, these are easier on
    # tokenized code (which we can't do before macro substitution).  I suspect the
    # tokenize module is C code, so folding this in with macro expansion might be less
    # hackish, but not necessarily faster.
    lineNumToComment = {}
    lineNumToClause = {}
    posToConstSrcStr = {}
    commentOnlyLines = set()
    # The tokenize module won't just take a text string.  It needs a utf-8 coded
    # readline function
    with io.BytesIO(text.encode('utf-8')) as f:
        tokens = tokenize.tokenize(f.readline)
        prevCommentLine = -1
        prevCommentCol = -1
        prevCommentContinuation = False
        prevKey = None
        wrap = False
        prevTokenWasString = None
        for token in tokens:
            if token.type == tokenize.COMMENT:
                startLine, startCol = token.start
                isLineComment = startCol == 0 or token.line[:startCol].isspace()
                if isLineComment:
                    commentOnlyLines.add(startLine)
                if len(token.string) > 1 and token.string[1] == " ":
                    commentText = token.string[2:]
                else:
                    # Most comments start "# ".  If not, capture the second character.
                    commentText = token.string[1:]
                if len(commentText) > 0 and commentText[-1] == '\\' and not forImport:
                    # A line continuation character at the end of a comment is was most
                    # likely added by the save code to indicate a wrapped line, but it
                    # can also be the second character of an escaped backslash from the
                    # user's original comment.  Stripping off the last char handles both.
                    commentText = commentText[:-1]
                ann = annotations.getByLineAndCol(startLine, startCol)
                if startLine == prevCommentLine + 1 and (prevCommentContinuation or
                        startCol == prevCommentCol and isLineComment and ann is None):
                    # Continuing previous comment, append to it
                    ann, prevText = lineNumToComment[prevKey]
                    if prevCommentContinuation:
                        lineSep = ''
                    else:
                        lineSep = '\n'
                    lineNumToComment[prevKey] = (ann, prevText + lineSep + commentText)
                else:
                    # Start of new comment
                    lineNumToComment[startLine] = (ann, commentText)
                    prevKey = startLine
                prevCommentLine = startLine
                prevCommentCol = startCol
                prevTokenWasString = None
                # We add a single backslash to indicate that we wrapped a line (which
                # then needs to be unwrapped).  We add a double backslashes to indicate
                # that the line actually ends in a backslash (which we need to preserve).
                prevCommentContinuation = not forImport and token.string[-1] == '\\' and (
                    len(token.string) == 1 or token.string[-2] != '\\')
            elif token.type == tokenize.NAME and token.string in ('elif', 'else',
                    'except', 'finally'):
                startLine, startCol = token.start
                lineNumToClause[startLine] = startCol
                prevTokenWasString = None
            elif token.type == tokenize.NUMBER:
                posToConstSrcStr[token.start] = token.string
            elif token.type == tokenize.STRING:
                if prevTokenWasString:
                    prevTokenWasString.append(token)
                    posToConstSrcStr[prevTokenWasString[0].start].append(token.string)
                else:
                    prevTokenWasString = [token]
                posToConstSrcStr[token.start] = [token.string]
            elif token.type == tokenize.NL:
                # NL is only emitted for newlines that do not end the statement
                # (continuation or blank line).
                startLine, startCol = token.start
                if startCol == 0 or token.line[:startCol].isspace():
                    # This is a blank line, log it in the comments list
                    lineNumToComment[startLine] = None, None
                    commentOnlyLines.add(startLine)
                # Note that specifically, we don't clear prevTokenWasString
            else:
                prevTokenWasString = None
    return lineNumToComment, lineNumToClause, posToConstSrcStr, commentOnlyLines

def _annotateAstWithComments(comments, clauses, commentOnlyLines, bodyAsts, startLine=0):
    elseCommentProperties = ('elselinecomments', 'elsestmtcomment')
    exceptCommentProperties = ('exceptlinecomments', 'exceptstmtcomment')
    finallyCommentProperties = ('finallylinecomments', 'finallystmtcomment')
    for stmt in bodyAsts:
        if hasattr(stmt, 'decorator_list'):
            # This is a function or class def with decorators.  Since decorators are on
            # lines before the definition, they (rather than the definition stmt) get the
            # comments that precede them.
            for decorator in stmt.decorator_list:
                cmntLns = _commentLinesBetween(comments, startLine, decorator.lineno)
                if cmntLns is not None:
                    decorator.linecomments = [comments[line] for line in cmntLns]
                cmntLns = _commentLinesBetween(comments, decorator.lineno,
                    decorator.end_lineno + 1)
                if cmntLns is not None:
                    # A comment on the same line with the decorator (assume only 1)
                    decorator.stmtcomment = comments[cmntLns[0]]
                    if len(cmntLns) > 1:
                        print('Dropped second stmt comment attached to decorator: %s' %
                            comments[cmntLns[1]], '...')
                startLine = decorator.end_lineno + 1
        commentLines = _commentLinesBetween(comments, startLine, stmt.lineno)
        if commentLines is not None:
            stmt.linecomments = [comments[line] for line in commentLines]
        # Block statements' line number range covers the entire code block below the stmt
        # so we examine all of the comments between the first line after the statement,
        # and the first line of the first statement of the body, and if any of them is
        # not on a line by itself, assume that's still part of the block owning stmt, but
        # anything following it is a line comment below it.  This will fail when the
        # first statement of the body shares a line with a multi-line block-owning stmt
        # (which will only appear in cases of really bad code formatting), and when
        # there's a comment all by itself on a line between parts of the block-owning
        # stmt and not followed by one that shares a line with it (which is also bad
        # formatting, but could happen in weird cases, and will simply relocate the
        # comment to after the stmt, which is acceptable).
        if hasattr(stmt, 'body'):
            firstBodyStmtLine = max(stmt.lineno+1, stmt.body[0].lineno)
            commentLines = _commentLinesBetween(comments, stmt.lineno, firstBodyStmtLine)
            lastStmtLine = stmt.lineno
            if commentLines is not None:
                for lineNum in commentLines:
                    if lineNum not in commentOnlyLines:
                        lastStmtLine = lineNum
                # Leave commentsLines with only those associated with the statement.
                # The rest will be handled in the recursive call to process the body.
                commentLines = [ln for ln in commentLines if ln <= lastStmtLine]
        else:
            lastStmtLine = stmt.end_lineno
            commentLines = _commentLinesBetween(comments, stmt.lineno, lastStmtLine+1)
        if commentLines is None or len(commentLines) == 0:
            pass
        elif len(commentLines) == 1:
            # There is only one comment associated with the entire statement, attach
            # it to the statement
            stmt.stmtcomment = comments[commentLines[0]]
        else:
            # There are multiple comments associated with statement:  Associate each with
            # the outermost AST node entirely confined to comment line.  If that fails,
            # or if stmt is a block stmt (for which _outermostAstOnLine gives up), just
            # assume it's one big statement comment.
            commentAsts = []
            for lineNum in commentLines:
                outerAst = _outermostAstOnLine(lineNum, stmt)
                if outerAst is None:
                    break
                commentAsts.append(outerAst)
            if len(commentAsts) == len(commentLines) and not NO_ICON_COMMENTS:
                for commentAst, line in zip(commentAsts, commentLines):
                    commentAst.iconcomment = comments[line]
            else:
                commentList = [comments[line][1] for line in commentLines]
                stmt.stmtcomment = comments[commentLines[0]][0], ' '.join(commentList)
        if hasattr(stmt, 'body'):
            # Recursively process statements in code block(s)
            _annotateAstWithComments(comments, clauses, commentOnlyLines, stmt.body,
                lastStmtLine + 1)
            startLine = stmt.end_lineno + 1
            # Process else/elif/except/finally clauses after if, for, while, and try.
            # Unfortunately, the relevant AST nodes don't record the location of these,
            # so we dig them out of the source code in _extractTokens and pass the
            # recorded location here via the "clauses" dictionary.  Location of these
            # statements is needed to properly place comments before vs. after vs. on
            # the else/elif/except/finally statement.
            clauseBodies = []
            if hasattr(stmt, 'handlers') and len(stmt.handlers) > 0:
                for i, handler in enumerate(stmt.handlers):
                    lp, sp = exceptCommentProperties
                    clauseBodies.append((stmt, lp + str(i), sp + str(i), handler.body))
            if hasattr(stmt, 'orelse') and len(stmt.orelse) > 0:
                s = stmt
                if isinstance(stmt, ast.If):
                    # For elif, the only thing in the orelse code block is the generated
                    # if AST.  Disassemble these back into elif blocks
                    while len(s.orelse) == 1 and isinstance(s.orelse[0], ast.If):
                        clauseBodies.append((s, *elseCommentProperties, s.orelse[0].body))
                        s = s.orelse[0]
                if len(s.orelse) > 0:
                    clauseBodies.append((s, *elseCommentProperties, s.orelse))
            if hasattr(stmt, 'finalbody') and len(stmt.finalbody) > 0:
                clauseBodies.append((stmt, *finallyCommentProperties, stmt.finalbody))
            bodyEnd = stmt.body[-1].end_lineno
            for clauseStmt, clauseLineProp,clauseStmtProp, clauseBody in clauseBodies:
                clauseStart = clauseBody[0].lineno
                clauseLine, _col = _findClauseBetween(clauses, bodyEnd + 1, clauseStart)
                if clauseLine is None:
                    # The clause statement is not on a separate line, attach following
                    # line comments to the first statement in its associated block
                    afterClauseLine = bodyEnd + 1
                else:
                    # A clause statement was found, attach comment lines before to the
                    # clauselinecomment property and comments on it to clausestmtcomment.
                    commentLines = _commentLinesBetween(comments, bodyEnd+1, clauseLine)
                    if commentLines is not None:
                        commentList = [comments[l] for l in commentLines]
                        setattr(clauseStmt, clauseLineProp, commentList)
                    if clauseLine in comments:
                        setattr(clauseStmt, clauseStmtProp, comments[clauseLine])
                    afterClauseLine = clauseLine + 1
                # Recursively process statements in the clause's code block (and line
                # comments between the clause statement and it.
                _annotateAstWithComments(comments, clauses, commentOnlyLines, clauseBody,
                    afterClauseLine)
                bodyEnd = clauseBody[-1].end_lineno
        else:
            startLine = lastStmtLine + 1
    return startLine

class ConstAnnotator(ast.NodeVisitor):
    def __init__(self, posToSrcTable):
        self.posToSrcTable = posToSrcTable
        ast.NodeVisitor.__init__(self)

    def visit_Constant(self, node):
        if isinstance(node, ast.Str):
            origStr = self.posToSrcTable.get((node.lineno, node.col_offset))
            if origStr is not None:
                node.annSourceStrings = origStr
        elif isinstance(node.value, numbers.Number):
            srcStr = self.posToSrcTable.get((node.lineno, node.col_offset))
            if srcStr is not None:
                node.annNumberSrcStr = srcStr
        ast.NodeVisitor.visit_Constant(self, node)

    def visit_JoinedStr(self, node):
        origStr = self.posToSrcTable.get((node.lineno, node.col_offset))
        if origStr is not None:
            node.annSourceStrings = origStr
        ast.NodeVisitor.generic_visit(self, node)

    def visit_FunctionDef(self, node):
        if len(node.body) > 0 and isinstance(node.body[0], ast.Expr):
            exprAst = node.body[0]
            if isinstance(exprAst.value, ast.Constant):
                constAst = exprAst.value
                if isinstance(constAst.value, str):
                    constAst.annIsDocString = True
        ast.NodeVisitor.generic_visit(self, node)

    def visit_ClassDef(self, node):
        if len(node.body) > 0 and isinstance(node.body[0], ast.Expr):
            exprAst = node.body[0]
            if isinstance(exprAst.value, ast.Constant):
                constAst = exprAst.value
                if isinstance(constAst.value, str):
                    constAst.annIsDocString = True
        ast.NodeVisitor.generic_visit(self, node)

def _annotateAstConsts(astPosToSrcTable, astNode):
    annotator = ConstAnnotator(astPosToSrcTable)
    annotator.visit(astNode)

def _commentLinesBetween(lineToCommentMap, startLine, endLine):
    commentList = None
    for lineNum in range(startLine, endLine):
        if lineNum not in lineToCommentMap:
            continue
        if commentList is None:
            commentList = []
        commentList.append(lineNum)
    return commentList

def _findClauseBetween(clauseMap, startLine, endLine):
    for line in range(startLine, endLine):
        if line in clauseMap:
            return line, clauseMap[line]
    return None, None

def _outermostAstOnLine(lineNum, exprAst):
    if hasattr(exprAst, 'body'):
        # We can't iterate over children with ast.iter_child_nodes, so just give up
        return None
    if hasattr(exprAst, 'lineno') and hasattr(exprAst, 'end_lineno') and \
            exprAst.lineno == lineNum and exprAst.end_lineno == lineNum:
        return exprAst
    else:
        for a in ast.iter_child_nodes(exprAst):
            outerAst = _outermostAstOnLine(lineNum, a)
            if outerAst is not None:
                return outerAst
    return None

class SegmentedText:
    """Holds save/clipboard .pyg text for an individual python statement, annotated with
    potential line breaks and their associated "level" in the hierarchy of the statement.
    Once collected, the wrapText method will produce an attractively (and compactly)
    wrapped version of the text."""
    __slots__ = ('segments', 'stmtComment')
    # Format for "segments" list is strings separated by numbers (break values).  break
    # values encapsulate the break "level", as well as how the break needs to be made
    # (with/without line continuation and string splitting).  Strings represent text to
    # be added to the file/clipboard, but can also be an object of class QuotedString
    # representing Python strings that can be internally wrapped if necessary.
    #
    # Break values are coded as: breakLevel * 100 + breakType.  The weird base-10 coding
    # is simply to make the values more human-readable (last two digits are type).
    # breakType is a value from 0 to 99 from the table below (needs-continue means that
    # if the code is wrapped, the line must end with a backslash (\) character):
    #   Code:
    #       00: code                    01: code needs-continue
    #   Single quoted strings:
    #       Ones digit is string type:
    #           0 = none, 1 = f, 2 = b, 3 = u, 4 = r, 5 = fr, 6 = br
    #       Tens digit combines quote type and needs-continue:
    #           10 = Single-quote string not needing continue
    #           20 = Double-quote string not needing continue
    #           30 = Single-quote string needing continue
    #           40 = Double-quote string needing continue
    #   Triple quoted strings:
    #       50 = Newline break (mandatory) with dedent to left margin
    #       51 = Non-newline (optional) break needing backslash escape with dedent to
    #            left margin
    #       52 = Newline break (mandatory) without dedent to left margin (help strings)
    #       53 = Non-newline break without dedent to left margin (help strings)

    def __init__(self, initialString=None):
        """Create a SegmentedText object.  initialString may be set to None or an empty
        string, to create an empty string, or to a normal text string.  It may also be
        set to a list of strings, and multiStringBreakLevel specified to initialize it
        to a series of strings punctuated with break-points of the specified level."""
        if initialString is None or initialString == "":
            self.segments = None
        else:
            self.segments = [initialString]
        self.stmtComment = None

    def add(self, breakLevel, text, needsContinue=False):
        """Append a single string to the end of the accumulated text.  If breakLevel
        is set to None, it will be appended directly to the last element of the text,
        without adding a break-point.  If breakLevel is specified as a number, the new
        text will be separated from the existing text by a break-point of that depth.
        Levels (depth values) start at low numbers (which confusingly mean higher levels
        in the hierarchy of the code) and increase with depth.  If needsContinue is
        specified as True, if the break-point is used, a continuation character '\'
        will be added at the end of the line, before the newline."""
        if self.segments is None:
            self.segments = [text]
        elif breakLevel is None:
            prevString = self.segments[-1]
            if type(prevString) is QuotedString:
                prevString.append(text)
            else:
                self.segments[-1] = prevString + text
        else:
            breakValue = _encodeBreakValue(breakLevel, 1 if needsContinue else 0)
            self.segments.append(breakValue)
            self.segments.append(text)

    def concat(self, breakLevel, otherSegText, needsContinue=False):
        """Append another SegmentedText object to the end of the accumulated text.  If
        breakLevel is set to None, it will merge the first element of the appended
        text with the last element of the text, without inserting a break-point between
        them. If breakLevel is specified as a number, the new text will be separated from
        the existing text by a break-point of that depth.  Levels (depth values) start at
        low numbers (which confusingly mean higher levels in the hierarchy of the code)
        and increase with depth.  If needsContinue is specified as True, if the break-
        point is used, a continuation character '\' will be added at the end of the line,
        before the newline."""
        if otherSegText.segments is None:
            return
        if self.segments is None:
            self.segments = otherSegText.segments[:]
        elif breakLevel is None:
            prevString = self.segments[-1]
            firstSeg = otherSegText.segments[0]
            if type(prevString) is QuotedString:
                if type(firstSeg) is QuotedString:
                    raise ValueError("Concatenating quoted strings not supported")
                prevString.append(firstSeg)
            elif type(firstSeg) is QuotedString:
                firstSeg.prepend(prevString)
                self.segments[-1] = firstSeg
            else:
                self.segments[-1] = prevString + otherSegText.segments[0]
            self.segments += otherSegText.segments[1:]
        else:
            breakValue = _encodeBreakValue(breakLevel, 1 if needsContinue else 0)
            self.segments.append(breakValue)
            self.segments += otherSegText.segments

    def addQuotedString(self, breakLevel, strType, strQuote, strContent, isDocString,
            needsContinue, stringBreakLevel=None):
        """Append a (single or double) quoted Python string or f-string to the accumulated
        text.  Like the "add" and "concat" methods, breakLevel may be specified as None
        to add without allowing a line break from the previous text segment.  However, if
        breakLevel is specified as None, stringBreakLevel (which would otherwise default
        to breakLevel + 1) must be specified.  Strings may not be concatenated to each
        other without a wrap point in between.  Specify isDocString for the special case
        of a triple-quote string whose continuation should not be dedented back to the
        left margin (currently, only Python help strings, but might be a worthwhile icon
        option for later)."""
        if stringBreakLevel is None:
            if breakLevel is None:
                raise ValueError("SegmentedText.addQuotedString with breakLevel = None "
                    "requires stringBreakLevel argument specified")
            stringBreakLevel = breakLevel + 1
        qs = QuotedString(strType, strQuote, strContent, isDocString, stringBreakLevel,
            needsContinue)
        if self.segments is None:
            self.segments = [qs]
            return
        if breakLevel is None:
            # Merge with last segment in list
            if type(self.segments[-1]) is QuotedString:
                raise ValueError("Concatenating quoted strings not supported")
            else:
                qs.prepend(self.segments[-1])
                self.segments[-1] = qs
        else:
            # Compute and append break value, followed by QuotedString object
            self.segments.append(_encodeBreakValue(breakLevel, 1 if needsContinue else 0))
            self.segments.append(qs)

    def addComment(self, comment, isStmtComment=False, annotation=None):
        """Add the content of a comment to the text.  Comment can be either in the form
        of a string, or a SegmentedText object holding the comment."""
        # Unlike strings, comments don't need to be integrated in to code wrapping, since
        # they can only be appended to the end of a statement.  Simply add placeholder to
        # preserve space for comment continuation and macro annotation, and record the
        # comment to be wrapped as a post-processing step.
        if isinstance(comment, SegmentedText):
            self.stmtComment = comment.stmtComment
        else:
            self.stmtComment = SegTextComment(comment, isStmtComment, annotation)
        if isStmtComment:
            macro = '' if self.stmtComment.macro is None else self.stmtComment.macro
            self.add(None, '  ' + macro + '# \\', needsContinue=False)

    def copy(self):
        """Segmented text is mutable, and it used in python-g with a less-than-rigorous
        assumption that if code returns a SegmentedText object, it is fair game to
        tack more on to it.  If you want to make sure one won't get extended, use this
        to create a shallow copy to return."""
        st = SegmentedText()
        st.segments = self.segments[:]

    def wrapText(self, startIndent, continuationIndent, margin=100, export=False):
        """Apply wrapping to the collected text.  Unlike a normal Python pretty-printer,
        compactness is favored over prettiness, so if lines can be saved by doing ugly
        wrapping, it will sometimes wrap in a less-ideal place."""
        # The method of wrapping is to first wrap stupidly at whatever wrap points will
        # pack the text the tightest.  This establishes a baseline for how few lines
        # the text can fit.  Once that is known, attempt to improve the appearance by
        # limiting wrapping to higher levels.  When the "tight" line count is exceeded,
        # choose the highest level wrapping that fit in the same number of lines.
        # While globally limiting the wrap-level works well for most Python statements,
        # it can be "fooled" by statements with multiple deeply-nested parts whose depth
        # is inconsistent, because the deep parts prevent good wraps to shallower ones
        # from ever being explored.
        if self.segments is None and self.stmtComment:
            return self.stmtComment.wrap(startIndent, margin, export=export)
        maxDepth = 0
        brkLvl = 0
        for s in self.segments:
            if type(s) is int:
                brkLvl, brkType = _decodeBreakValue(s)
                maxDepth = max(maxDepth, brkLvl)
            elif type(s) is QuotedString:
                maxDepth = max(maxDepth, brkLvl + 1)  # A string can be further broken
        # Remove QuotedString objects representing breakable strings, and (if necessary),
        # break them down at word boundaries
        self._breakStrings(startIndent, continuationIndent, margin)
        # Baseline with no level cutoff
        breakPointList = self._findAllBreakPoints(maxDepth + 1, startIndent,
            continuationIndent, margin)
        minLines = len(breakPointList) + 1
        # Improve by attempting to decrement level cutoff
        if minLines > 1:
            for levelCutoff in range(maxDepth, 1, -1):
                levelBPs = self._findAllBreakPoints(levelCutoff, startIndent,
                    continuationIndent, margin)
                nLines = len(levelBPs) + 1
                if nLines > minLines:
                    break
                breakPointList = levelBPs
        # Use the computed break point list to build the string
        startIdx = 0
        strings = [' ' * startIndent]
        for bp in breakPointList:
            breakLevel, breakType = _decodeBreakValue(self.segments[bp])
            # Copy the strings before the breakpoint to strings
            for i in range(startIdx, bp, 2):
                strings.append(self.segments[i])
            # If continuation and/or string splitting is needed, add it
            strings.append(_breakPrefix(breakType))
            # Append the newline and continuation indent (triple quoted strings get
            # no indent, unless they are docstrings, which get startIndent)
            strings.append('\n')
            if breakType < 50:
                strings.append(' ' * continuationIndent)
            elif breakType in (52, 53):
                strings.append(' ' * startIndent)
            # If string continuation was used, restart the string
            strings.append(_breakSuffix(breakType))
            startIdx = bp + 1
        # Copy the text after the last break point
        for i in range(startIdx, len(self.segments), 2):
            strings.append(self.segments[i])
        joinedString = "".join(strings)
        # If there's a statement comment, wrap it and add it to the end of the completed
        # string
        if self.stmtComment:
            return self.stmtComment.wrap(continuationIndent +  STMT_COMMENT_INDENT,
                margin, appendToStmt=joinedString, export=export)
        return joinedString

    def _findAllBreakPoints(self, levelCutoff, startIndent, continueIndent, margin):
        startIdx = 0
        tempTripleQuoteDedent = 0
        continueIndentAdded = False
        breakPoints = []
        while True:
            breakPoint = self._findBreakPoint(startIdx, levelCutoff,
                startIndent - tempTripleQuoteDedent, margin)
            if breakPoint is None:
                break
            breakPoints.append(breakPoint)
            startIdx = breakPoint + 1
            _breakLvl, breakType = _decodeBreakValue(self.segments[breakPoint])
            if not continueIndentAdded:
                startIndent = continueIndent
                startIndent += len(_breakSuffix(breakType))
                continueIndentAdded = True
            if breakType in (50, 51):
                tempTripleQuoteDedent = startIndent
            else:
                tempTripleQuoteDedent = 0
        return breakPoints

    def _findBreakPoint(self, startIdx, levelCutoff, startIndent, margin):
        """ Find the last point where the string can be broken before the given margin"""
        lastAcceptableBreakPoint = startIdx + 1
        if lastAcceptableBreakPoint >= len(self.segments):
            return None
        textWidth = startIndent
        for i in range(startIdx, len(self.segments), 2):
            string = self.segments[i]
            if i+1 < len(self.segments) and _decodeBreakValue(self.segments[i+1])[1] > 1:
                # For strings, trailing spaces are part of the data (don't lop them off).
                lastCharIsSpace = False
            else:
                lastCharIsSpace = string[-1] == ' '
            stringRequiredWidth = len(string) - (1 if lastCharIsSpace else 0)
            if i+1 >= len(self.segments):
                # We reached the end of the statement and it either fits or does not
                if textWidth + stringRequiredWidth <= margin:
                    return None
                else:
                    return lastAcceptableBreakPoint
            breakLevel, breakType = _decodeBreakValue(self.segments[i + 1])
            if breakLevel < levelCutoff:
                stringRequiredWidth += len(_breakPrefix(breakType))
                if textWidth + stringRequiredWidth > margin:
                    return lastAcceptableBreakPoint
                lastAcceptableBreakPoint = i + 1
            if breakType in (50, 52):  # Mandatory break at newline
                return i + 1
            textWidth += len(string)
        return None  # Because of odd length of segList, this will not be reached

    def _breakStrings(self, startIndent, continueIndent, margin):
        """Measure the length of the text, and if it exceeds what will fit within the
        given parameters (margin - continueIndent for most things), break quoted string
        objects at word boundaries (and non-word boundaries based on on the calculated
        maximum length.  Triple-quoted strings break the rules, in that their indent for
        continuation is either all the way to the left margin, or to startIndent instead
        of continueIndent for doc-strings."""
        totalLength = 0
        for entry in self.segments:
            if type(entry) is not int:
                totalLength += len(entry)
        fitsOnLine = totalLength < margin - startIndent
        # Break strings at word boundaries (or as necessary to fit within maxLength)
        newSegments = []
        for entry in self.segments:
            if isinstance(entry, QuotedString):
                newSegments += entry.breakString(startIndent, continueIndent,
                    margin, fitsOnLine)
            else:
                newSegments.append(entry)
        self.segments = newSegments

class QuotedString:
    """Helper object for SegmentedText to hold Python quoted strings.  Strings are
    distinct from other code objects in that they are internally wrappable.  They are
    held in unwrapped form, until it is known whether the line will need wrapping at
    all.  If the line needs no wrapping, the string can be returned returned as-is using
    the unbrokenString method.  If the line will need wrapping, the breakString method
    will split it at word boundaries (and based on maxLength, within word boundaries
    if any of the remaining "words" exceed that limit).  breakString returns the split
    string in SegmentedText's "segments" format, so the SegmentedText wrapText method
    can wrap the string along with everything else it's wrapping."""
    __slots__ = ('strType', 'quote', 'text', 'breakLevel', 'breakType', 'prependedText',
        'appendedText')

    def __init__(self, strType, strQuote, text, isDocString, brkLvl, needsCont):
        self.breakType = _encodeStringBreakType(strType, strQuote, isDocString, needsCont)
        self.strType = strType
        self.quote = strQuote
        self.text = text
        self.breakLevel = brkLvl
        self.prependedText = ""
        self.appendedText = ""

    def __len__(self):
        """Return the length of the quoted string (including quotes) assuming no
        line breaks are added."""
        return len(self.strType) + 2 * len(self.quote) + len(self.text) + \
            len(self.prependedText) + len(self.appendedText)

    def breakString(self, startIndent, continueIndent, margin, fitsOnLine):
        """Split the string at the end of whitespace of word boundaries, and return a
        SegmentedText.segments-style list that can be spliced-in in place of the
        QuotedString object in the list.  Strings longer than will fit between the
        given indents and margin are also split, even if they don't have whitespace.
        The maximum length depends upon the string type and whether it is the initial
        or subsequent portion of the string (triple-quoted strings dedent either back
        to the left margin, or to startIndent if they are doc-strings).  Set fitsOnLine
        to True to save work if the stated (by len()) total length of the string will fit
        on the line, but we may still break the line, if it is a doc-string containing
        one or more newline characters, since that will need reindenting by the caller."""
        if fitsOnLine and self.breakType != 53 or (self.breakType == 53 and
                '\n' not in self.text):
            return [self.unbrokenString()]
        foundSpace = False
        segmentStrings = []
        startIdx = 0
        stringStart = self.prependedText + self.strType + self.quote
        maxFirstSegLen = max(margin - continueIndent, len(stringStart) + 1)
        for i, c in enumerate(self.text):
            if c == '\n':
                segmentStrings.append(stringStart + self.text[startIdx:i+1])
                stringStart = ""
                startIdx = i+1
                foundSpace = False
            elif c.isspace():
                foundSpace = True
            elif foundSpace:
                segmentStrings.append(stringStart + self.text[startIdx:i])
                stringStart = ""
                startIdx = i
                foundSpace = False
        segmentStrings.append(stringStart + self.text[startIdx:] + self.quote +
            self.appendedText)
        # Adjust maxLength for continuation characters needed, to a minimum of 5
        # characters (at that point we give up and exceed the requested margin),
        # and for triple quotes which dedent all the way to the left margin.
        if self.breakType == 51:
            maxLength = margin
        elif self.breakType == 53:
            maxLength = margin - startIndent
        else:
            maxLength = margin - continueIndent
        maxLength -= len(_breakPrefix(self.breakType)) + \
                     len(_breakSuffix(self.breakType))
        if maxLength < 5:
            maxLength = 5
        # add breakValue between segments, and if any segments are still longer than
        # maxLength, break those, further
        segments = []
        brkValue = _encodeBreakValue(self.breakLevel, self.breakType)
        for i, string in enumerate(segmentStrings):
            maxSegLength = maxFirstSegLen if i == 0 else maxLength
            if len(string) > maxSegLength:
                startIdx = 0
                while len(string) - startIdx > maxSegLength:
                    segments.append(string[startIdx:startIdx + maxSegLength])
                    segments.append(brkValue)
                    startIdx += maxSegLength
                segments.append(string[startIdx:])
            else:
                segments.append(string)
            if i < len(segmentStrings) - 1:
                if segments[-1][-1] == '\n':
                    # Triple quoted string line ending: strip off newline and add a
                    # mandatory break (type 50 or 53)
                    segments[-1] = segments[-1][:-1]
                    segments.append(self.breakType - 1)
                else:
                    segments.append(brkValue)
        return segments

    def unbrokenString(self):
        return self.prependedText + self.strType + self.quote + self.text + self.quote + \
               self.appendedText

    def append(self, text):
        self.appendedText += text

    def prepend(self, text):
        self.prependedText = text + self.prependedText

class SegTextComment:
    """Helper object for SegmentedText to hold comments and their related settings."""
    __slots__ = ('text', 'macro')
    def __init__(self, text, isStmtComment=False, annotation=None):
        if isStmtComment:
            self.text = text.replace('\n', '\\n')
        else:
            self.text = text
        self.macro = None if annotation is None else ('$:' + annotation + '$')

    def wrap(self, indent, margin, appendToStmt=None, export=False):
        """Wraps comment text, indenting to indent and wrapping at margin.  Optionally,
        (if appendToStmt is not None) append comment text to an (already processed into
        string form) statement."""
        # Wrap the text of the comment at the margin, adding extra newlines where
        # marked with hard newlines.  The textwrap module almost does what we want,
        # except for its handling of embedded newlines, so we can only use it
        # per-newline-terminated-line rather than on all of the lines together.
        indentString = (indent * " ")  + "# "
        lineWrapMargin = margin - (indent + 3)
        if appendToStmt is None and self.macro is None:
            firstLineWrapMargin = lineWrapMargin
        else:
            if appendToStmt is None and self.macro is not None:
                appendToStmt = (indent * " ") + self.macro + '# \\'
            elif len(appendToStmt) < 5 or appendToStmt[-5:] != '  # \\':
                print('SegTextComment did not find expected placeholder in stmt text')
                appendToStmt += '  # \\'
            index = appendToStmt.rfind('\n')
            if index == -1:
                index = 0
            firstLineWrapMargin = margin - (len(appendToStmt) - index)
        origLines = self.text.split("\n")
        if not export:
            escapeLineContinuations(origLines)
        continueWrap = '\\\n' + indentString
        nonContinueWrap = '\n' + indentString
        wrappedLines = []
        perLineMargin = firstLineWrapMargin
        for i, line in enumerate(origLines):
            if len(line) <= perLineMargin + 1:
                # If the line does not need to be wrapped, save work and gain one
                # additional space without continuation character.
                wrappedLine = line
            else:
                words = comn.splitWords(line)
                wrappedLine = continueWrap.join(comn.wordWrap(words, lineWrapMargin,
                    firstLineMax=perLineMargin, lastLineMax=lineWrapMargin+1))
            perLineMargin = lineWrapMargin
            wrappedLines.append(wrappedLine)
        outText = nonContinueWrap.join(wrappedLines)
        if appendToStmt is not None:
            return appendToStmt[:-1] + outText
        return indentString + outText

def _decodeBreakValue(breakValue):
    brkLevel = breakValue // 100
    brkType = breakValue - brkLevel * 100
    return brkLevel, brkType

def _encodeBreakValue(breakLevel, breakType):
    return breakLevel * 100 + breakType

def _encodeStringBreakType(strType, quote, isDocString, needsContinue):
    if len(quote) == 1:
        typeDigit = {'': 0, 'f': 1, 'b': 2, 'u': 3, 'r': 4, 'fr': 5, 'br': 6, 'rf': 5,
            'rb': 6}[strType]
        quoteContDigit = {"'": 10, '"': 20}[quote] + (20 if needsContinue else 0)
        return typeDigit + quoteContDigit
    # For triple quoted strings, string and quote types and need for continuation are not
    # encoded in the break type, since we don't have to restart the string after a wrap.
    if isDocString:
        return 53
    return 51

def _decodeStringBreakType(breakType):
    quoteContDigit = breakType // 10
    if quoteContDigit == 5:
        return None, '"""', None
    typeDigit = breakType - quoteContDigit * 10
    strType = {0:'', 1:'f', 2:'b', 3:'u', 4:'r', 5:'fr', 6:'br'}[typeDigit]
    quote = "'" if quoteContDigit in (1, 3) else '"'
    needsCont = quoteContDigit in (3, 4)
    return strType, quote, needsCont

def _breakPrefix(breakValue):
    breakLvl, breakType = _decodeBreakValue(breakValue)
    if breakType < 10:
        return '' if breakType == 0 else ' \\'
    if breakType in (50, 52):
        return ''
    if breakType in (51, 53):
        return '\\'
    if 10 <= breakType <= 49:
        strType, quote, needsCont = _decodeStringBreakType(breakType)
        return quote + (' \\' if needsCont else '')

def _breakSuffix(breakValue):
    breakLvl, breakType = _decodeBreakValue(breakValue)
    if breakType < 10 or breakType >= 50:
        return ''
    strType, quote, needsCont = _decodeStringBreakType(breakType)
    return strType + quote

def _parsePosMacro(macroArgs):
    match = posMacroPattern.match(macroArgs)
    if match is None:
        print("Bad format for @ (segment position) macro")
        return 0, 0
    x = int(match.group(1))
    y = int(match.group(3))
    return x,y

def loadFile(macroParser, fileName, forImport=False):
    with open(fileName, "r") as f:
        return parseText(macroParser, f.read(), fileName, forImport)

def syntaxErrDialog(excep, lineNumTranslate, originalText):
    caretLine = " " * (excep.offset-1) + "^"
    message = "%s: %s\n%s%s\n" % (excep.__class__.__name__,
            str(excep), excep.text, caretLine)
    origLineNum = lineNumTranslate[excep.lineno-1]
    message += "Expanded from input file line %d:\n%s" % (origLineNum,
            numberedLine(originalText, origLineNum))
    print(message)

def parseFailDialog(excep):
    message = "Parsing failed %s: %s" % (excep.__class__.__name__, str(excep))
    print(message)

def macroFailDialog(text, idx, lineNum, message=None):
    if message is None:
        macroEnd = text.find('$', idx + 1)
        if macroEnd == -1:
            macro = text[idx:idx+10] + '...'
        elif macroEnd - idx > 100:
            macro = text[idx:idx+100] + '...'
        else:
            macro = text[idx:macroEnd+1]
        message = "Unrecognized macro on line %d: %s" % (lineNum, macro)
    else:
        message = "%s, line %d" % (message, lineNum)
    for i in range(idx, -1, -1):
        if text[i] == '\n':
            lineStart = i + 1
            break
    else:
        lineStart = 0
    caretLine = " " * (idx - lineStart) + "^"
    lineEnd = text.find('\n', idx)
    if lineEnd == -1:
        lineEnd = len(text)
    lineText = text[lineStart:lineEnd]
    message += "\n%s\n%s" % (lineText, caretLine)
    print(message)

def numberedLine(text, lineNum):
    """Return a single line (lineNum) from text.  Note, that this inefficiently scans
    the entire text for newlines to find the specified line."""
    startIdx = 0
    for i in range(lineNum-1):
        startIdx = text.find('\n', startIdx)
        if startIdx == -1:
            return ""
        startIdx += 1
    endIdx = text.find('\n', startIdx)
    if endIdx == -1:
        return text[startIdx:]
    return text[startIdx:endIdx]

def countLinesAndCols(text, endPos, startLine, startCol):
    line = startLine
    col = startCol
    for i, c in enumerate(text):
        if i >= endPos:
            return line, col
        if c == '\n':
            col = 0
            line += 1
        else:
            col += 1
    return line, col

def escapeLineContinuations(lines):
    """Turn trailing backslash on strings in parameter lines to double backslash."""
    for i, line in enumerate(lines):
        if len(line) > 0 and line[-1] == '\\':
            lines[i] += '\\'

def strAt(text, start, str):
    """Safely execute: text[start:start+len(str)] == str when start might be before start
    of text. """
    if start < 0:
        return False
    return text[start:start+len(str)] == str

def _moduleTest():
    macroParser = MacroParser()
    macroParser.addMacro("l1", "", countLinesAndCols)
    macroParser.addMacro("testSubs", '"testing substitution"', numberedLine)
    macroParser.addMacro("testDollar", 'nert.asdf$.wang.thing(wang)')
    macroParser.addMacro("testDollarEnd", "3+$")
    macroParser.addMacro("if", "if a == $2:\n        pass")
    text="""$@-1+34$
$:v$[a, b, c]
$@+2+34$
$:for$for i in range(3):
    print(i $:v$+ 1 $:h$* $testDollarEnd$42)
    $testSubs$
    $if:macroifconst$
    print(a$:subscript$[1], $:kwd$end=2)
    a = $:gencomp$(x for x in range(3)), $:dict${a:1, b:2}
    a $:augassign$+= i $:inline if$if i $:is$is 0 else $:unary$-i
    $testDollar$
    $:if$if i $:compare$== 1:
        pass
    $:elif$elif i==2:
        pass
    $:else$else:
        pass
    $l1:
l2$pass
"""
    print('original text:\n%s\n' % text)
    segments = parseText(macroParser, text, 'nurdle.py')

    if segments is not None:
        for segment in segments:
            pos, stmtList = segment
            print(repr(pos))
            for stmt in stmtList:
                for node in ast.walk(stmt):
                    macroName = macroArgs = iconCreateFn = None
                    if hasattr(node, 'macroName'):
                        print('annotated node %s with macro name %s' %
                            (node.__class__.__name__, node.macroName))
                    if hasattr(node, 'macroArgs'):
                        print('annotated node %s with macro args %s' %
                              (node.__class__.__name__, node.macroArgs))
                    if hasattr(node, 'iconCreationFunction'):
                        print('annotated node %s with icon creation function %s' %
                              (node.__class__.__name__, repr(node.iconCreationFunction)))
                astpretty.pprint(stmt)

def outFormatTest():
    segText = SegmentedText("asdf")
    segText.add(None, "(")
    segText.add(2, "$:w$")
    segText.addQuotedString(None,'fr', '"', 'this is a long string with lots of words '
        'it. I am going to keep typing and typing until I have oooooooooooooooooooooo '
        'something really long and hard to fit within the margin.  Lets do lot\'s of '
        'wrapping!  Here I go, lots more text coming.  Lots of love: xxxxxxxxxxxxxxxx'
        'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', False, True, 2)
    segText.add(2 , ", ")
    segText.addQuotedString(None,'r', '"""',
    """Add a macro to annotate and extend the save-file and pasted-text format beyond
the base Python syntax.  The save-file format extends Python with macros of the
form $name:argString$.  name is composed of the same set of characters as Python
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
identifiers. Macros that skip the name ($:args$) provide (mostly layout-ralated)
information to the built-in icon creation functions for Python itself.  The colon
separates the macro name from its arguments, and may be omitted if there are no
arguments to pass.  The format of the argument string (argString) is entirely up
to the implementer, but must not contain the "$" character.""", False, True, 2)

    segText.add(None, ", ")
    fakeSegText = SegmentedText("deleteme")
    fakeSegText.segments = ["asdf, ",200,"nert(",300, "wang, ",300, "blort), ",201,
        "bbbbb + ", 300, "45 * ", 400, "3) + ", 101, "10 * ", 201, "2 ** ", 301, "4"]
    segText.concat(2, fakeSegText)
    print(repr(segText.segments))
    for margin in range(12, 100, 4):
        print("-"*margin, margin)
        savedSegments = segText.segments[:]  # Wrapping can only be done once
        print(segText.wrapText(4, 8, margin))
        segText.segments = savedSegments
# outFormatTest()
#_moduleTest()